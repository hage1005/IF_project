{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fa6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56f2152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/kewen/IF_project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8161fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19d5ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaochen/anaconda3/envs/IFv2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from tkinter import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision import models\n",
    "from src.data_utils.MnistDataset import MnistDataset\n",
    "from src.utils.utils import save_json\n",
    "from src.data_utils.Cifar10Dataset import Cifar10Dataset\n",
    "from src.solver.fenchel_solver import FenchelSolver\n",
    "from src.modeling.classification_models import CnnCifar, MNIST_1\n",
    "from src.modeling.influence_models import Net_IF, MNIST_IF_1\n",
    "from torch.autograd.functional import hessian\n",
    "from torch.nn.utils import _stateless\n",
    "from torch.nn import CrossEntropyLoss \n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import yaml\n",
    "YAMLPath = 'src/config/MNIST/default.yaml'\n",
    "\n",
    "def get_single_image_from_dataset(dataset, idx):\n",
    "        x, y = dataset[idx]\n",
    "        x = x.unsqueeze(0)\n",
    "        y = torch.LongTensor([y])\n",
    "        return x, y\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f2ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--YAMLPath\", type=str)\n",
    "args, unknown = parser.parse_known_args()\n",
    "if args.YAMLPath:\n",
    "    YAMLPath = args.YAMLPath\n",
    "with open(YAMLPath) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "args= Struct(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da38973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples with label '0': 100\n",
      "number of examples with label '1': 100\n",
      "number of examples with label '2': 100\n",
      "number of examples with label '3': 100\n",
      "number of examples with label '4': 100\n",
      "number of examples with label '5': 100\n",
      "number of examples with label '6': 100\n",
      "number of examples with label '7': 100\n",
      "number of examples with label '8': 100\n",
      "number of examples with label '9': 100\n",
      "loaded train_dataset with 1000 samples\n",
      "loaded dev FolderDataset with 10 files in folder, \n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(args._ckpt_dir, args._pretrain_ckpt_name)\n",
    "inv_hessian_path = os.path.join(args._ckpt_dir, \"numpy_inv_hessian_\" + args._pretrain_ckpt_name)\n",
    "\n",
    "if args.dataset_name == 'cifar10':\n",
    "    Dataset = Cifar10Dataset\n",
    "elif args.dataset_name == 'mnist':\n",
    "    Dataset = MnistDataset\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "class_label_dict = Dataset.get_class_label_dict()\n",
    "CLASS_MAP = Dataset.get_class_map()\n",
    "train_classes = [class_label_dict[c] for c in args.train_classes]\n",
    "ImageDataset = Dataset(args.dev_original_folder, args.dev_transformed_folder, args.test_original_folder, args.test_transformed_folder, train_classes, args.num_per_class)\n",
    "\n",
    "train_dataset, train_dataset_no_transform = ImageDataset.get_train()\n",
    "dev_dataset, dev_dataset_no_transform = ImageDataset.get_dev()\n",
    "train_dataset_size = len(train_dataset)\n",
    "if args.classification_model == 'Resnet34':\n",
    "    classification_model = models.resnet34(pretrained=True).to('cuda')\n",
    "    classification_model.fc = torch.nn.Linear(\n",
    "        classification_model.fc.in_features,\n",
    "        10).to('cuda')\n",
    "elif args.classification_model == 'CnnCifar':\n",
    "    classification_model = CnnCifar(10).to('cuda')\n",
    "elif args.classification_model == 'MNIST_1':\n",
    "    classification_model = MNIST_1(args._hidden_size_classification, 10).to('cuda')\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "if os.path.isfile(file_path):\n",
    "    checkpoint = torch.load(file_path, map_location='cuda')\n",
    "    global_epoch = checkpoint['epoch']\n",
    "    classification_model.load_state_dict(checkpoint['model_states']['classification'])\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(file_path))\n",
    "\n",
    "x_dev, y_dev = get_single_image_from_dataset(\n",
    "    dev_dataset, args.dev_id_num)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3759e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params):\n",
    "    print(params.shape)\n",
    "    params_splitted_reshaped = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for shape in shapes:\n",
    "        end +=  np.prod(shape)\n",
    "        print(start, end)\n",
    "        params_splitted_reshaped.append(params[start:end].reshape(shape))\n",
    "        start = end\n",
    "    inputs = train_dataset[:][0].to('cuda')\n",
    "    labels = train_dataset[:][1].to('cuda')\n",
    "    out: torch.Tensor = _stateless.functional_call(classification_model, \\\n",
    "        {n: p for n, p in zip(names, params_splitted_reshaped)}, inputs)\n",
    "    loss = criterion(out, labels)\n",
    "    return loss\n",
    "\n",
    "def loss_grad_at_point(model, x, y):\n",
    "    # w should be torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "    # train_point should be alpha_train_dataset[0], a tuple of image and label\n",
    "    out = model(x)\n",
    "    loss = criterion(out, torch.tensor([y]).to('cuda'))\n",
    "    loss.backward()\n",
    "    grad = torch.cat(tuple([_.grad.view(-1) for _ in model.parameters()]))\n",
    "    for p in classification_model.parameters():\n",
    "        p.grad = None\n",
    "    return grad\n",
    "\n",
    "def calculate_if(x_train, y_train, x_test, y_test, inv_Hessian):\n",
    "    # test point should be alpha_test_dataset[10]\n",
    "\n",
    "    test_loss = loss_grad_at_point(classification_model, x_train, y_train).to(\"cpu\").numpy()\n",
    "\n",
    "    train_loss = loss_grad_at_point(classification_model, x_test, y_test).to(\"cpu\").numpy()\n",
    "\n",
    "    if_score = -np.matmul(np.matmul(test_loss.T, inv_Hessian), train_loss)\n",
    "\n",
    "    return if_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab935bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = x_dev.to('cuda')\n",
    "y_dev = y_dev.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bccfa00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25450])\n",
      "0 25088\n",
      "25088 25120\n",
      "25120 25440\n",
      "25440 25450\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(n \u001b[38;5;28;01mfor\u001b[39;00m n, _ \u001b[38;5;129;01min\u001b[39;00m classification_model\u001b[38;5;241m.\u001b[39mnamed_parameters())\n\u001b[1;32m      2\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m classification_model\u001b[38;5;241m.\u001b[39mparameters()] \u001b[38;5;66;03m# a parameter for loss function, not passed explicitly\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m Hessian \u001b[38;5;241m=\u001b[39m \u001b[43mhessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclassification_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m np_Hessian \u001b[38;5;241m=\u001b[39m Hessian\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m/\u001b[39mtrain_dataset_size\n\u001b[1;32m      5\u001b[0m damping_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdiag(np\u001b[38;5;241m.\u001b[39mfull(Hessian\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m0.01\u001b[39m),\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:808\u001b[0m, in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[1;32m    805\u001b[0m     _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jac\n\u001b[0;32m--> 808\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m               \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_jacobian_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:670\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    668\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[0;32m--> 670\u001b[0m     vj \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)):\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:159\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_grad_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "names = list(n for n, _ in classification_model.named_parameters())\n",
    "shapes = [p.shape for p in classification_model.parameters()] # a parameter for loss function, not passed explicitly\n",
    "Hessian = hessian(loss, torch.cat(tuple([_.view(-1) for _ in classification_model.parameters()])))\n",
    "np_Hessian = Hessian.to(\"cpu\").numpy()/train_dataset_size\n",
    "damping_matrix = np.diag(np.full(Hessian.shape[0],0.01),0)\n",
    "damping_hessian = np_Hessian + damping_matrix\n",
    "inv_hessian = np.linalg.inv(damping_hessian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a12d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8df25329",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(inv_hessian_path, inv_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18d761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_hessian = np.load(inv_hessian_path+\".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce85f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 1000/1000 [03:18<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "if_score_list = []\n",
    "for i in tqdm(range(train_dataset_size)):\n",
    "    if_score = calculate_if(train_dataset[i][0].to('cuda'), train_dataset[i][1].to('cuda'), x_dev, y_dev, inv_hessian)\n",
    "    if_score_list.append(if_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf84b4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.20505717373774218,\n",
       " -0.13675323938152464,\n",
       " 1.4618436422043177,\n",
       " -0.5783401893822859,\n",
       " 0.29210114835316525,\n",
       " -2.9287083337700874,\n",
       " -2.396179142163878,\n",
       " -0.0644562128974485,\n",
       " -19.26733133274052,\n",
       " -0.33017337495914173,\n",
       " -0.048070874162933014,\n",
       " -0.3448035323548823,\n",
       " 12.35140544530747,\n",
       " -3.5751157135686222,\n",
       " 0.2589196204763886,\n",
       " -7.994136526653134,\n",
       " -0.4977308160684129,\n",
       " -0.3000613195430474,\n",
       " -4.1247700115402655,\n",
       " 2.1935133508446367,\n",
       " -0.03815414746735604,\n",
       " -1.2846074971721193,\n",
       " 0.35292067823664053,\n",
       " -0.03627522050488789,\n",
       " -7.01181707883838,\n",
       " -43.54676256936907,\n",
       " -0.07032658716526022,\n",
       " -2.357623081620661,\n",
       " 5.219364308945186,\n",
       " -0.8521883975233764,\n",
       " -0.0940683571280373,\n",
       " -1.5727824198900024,\n",
       " -28.901703810919532,\n",
       " -0.09899149752045851,\n",
       " -3.6186159343362254,\n",
       " -10.889226175547146,\n",
       " -1.1497048673995158,\n",
       " -4.639582988899004,\n",
       " -1.3576957689389293,\n",
       " -0.3339848332074453,\n",
       " 1.0026317520344112,\n",
       " -0.08931735805444588,\n",
       " 0.0009021972074156311,\n",
       " -2.063734903857029,\n",
       " -1.4200960209459565,\n",
       " 0.11127518320040841,\n",
       " 0.6542837840342945,\n",
       " -0.2678442577000424,\n",
       " -0.10307996646559717,\n",
       " -0.4897545676474556,\n",
       " -4.204225378507028,\n",
       " 6.144779172617696,\n",
       " -11.389743799793647,\n",
       " -1.5471444371472758,\n",
       " 3.5749525096382944,\n",
       " -0.010326488033246553,\n",
       " -0.26280924388149607,\n",
       " -0.01675349369705535,\n",
       " -0.6594049952044475,\n",
       " -0.09843835500087028,\n",
       " -0.4870518374294469,\n",
       " -1.9873720685292207,\n",
       " -0.09089279099520498,\n",
       " -1.7364643968170048,\n",
       " -0.0622814005511181,\n",
       " -0.01945224618726087,\n",
       " -0.026243808156590907,\n",
       " -0.6532881267011549,\n",
       " -0.391852491094674,\n",
       " 0.7476280934114361,\n",
       " -0.25730566160360846,\n",
       " -15.422673909915055,\n",
       " -1.553279720294415,\n",
       " -0.10338787949254236,\n",
       " -3.728271808106998,\n",
       " -0.4405173440788441,\n",
       " -0.0010196263703358688,\n",
       " -0.4279417251388449,\n",
       " 1.1858233568172816,\n",
       " -0.08435358606638811,\n",
       " -1.4456398418957024,\n",
       " -21.879890274241493,\n",
       " -2.675620071579188,\n",
       " -0.08009037097034478,\n",
       " -0.2403253381855448,\n",
       " -0.34798855936738826,\n",
       " -1.8666308511622924,\n",
       " 2.644913155856605,\n",
       " -3.60618783801906,\n",
       " -0.11618194326191755,\n",
       " 2.226825910590804,\n",
       " -0.25683392852010545,\n",
       " -0.3507265518570909,\n",
       " -2.8152123920678953,\n",
       " -0.13472223757251972,\n",
       " -0.016058090205681788,\n",
       " -0.0645580475234292]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "018c0329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25450, 25450])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hessian.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2f577e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "torch.Size([1000])\n",
      "torch.Size([1000, 10])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "def CE_loss_new_all2(w, hidden_size=32):\n",
    "    divide1 = hidden_size*784\n",
    "    divide2 = divide1 + hidden_size\n",
    "    divide3 = divide2 + hidden_size*10\n",
    "    \n",
    "    images = train_dataset[:][0]\n",
    "    labels =  train_dataset[:][1]\n",
    "\n",
    "    out1 = F.linear(images.reshape(-1, 784).to(device), w[:divide1].reshape(hidden_size,784), w[divide1:divide2])\n",
    "    out2 = F.relu(out1)\n",
    "    out3 = F.linear(out2, w[divide2:divide3].reshape(10,hidden_size), w[divide3:])\n",
    "    loss = criterion(out3, labels.to(device))\n",
    "    print(criterion)\n",
    "    print(labels.shape)\n",
    "    print(out3.shape)\n",
    "    print(loss.shape)\n",
    "    return loss\n",
    "names = list(n for n, _ in classification_model.named_parameters())\n",
    "shapes = [p.shape for p in classification_model.parameters()]\n",
    "Hessian2 = hessian(CE_loss_new_all2, torch.cat(tuple([_.view(-1) for _ in classification_model.parameters()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594da4a",
   "metadata": {},
   "source": [
    "# my implemetation loss grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "9a27fece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_grad_at_point(model, x, y):\n",
    "    # w should be torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "    # train_point should be alpha_train_dataset[0], a tuple of image and label\n",
    "    out = model(x)\n",
    "    print(out)\n",
    "    loss = criterion(out, torch.tensor([y]).to(device))\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    grad = torch.cat(tuple([_.grad.view(-1) for _ in model.parameters()]))\n",
    "    for p in classification_model.parameters():\n",
    "        p.grad = None\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f5bf6636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.5083,  5.2741,  0.5708, -0.1582, -0.4546, -0.0932,  0.7715,  0.6345,\n",
      "          0.1679, -0.3296]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.0507, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0022, -0.0022, -0.0022,  ...,  0.0092,  0.0058,  0.0035])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= loss_grad_at_point(classification_model, x_dev, y_dev)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264bf733",
   "metadata": {},
   "source": [
    "# Xuhui implement loss grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2bf22e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_grad_at_point(w, train_point, hidden_size = 32):\n",
    "    # w should be torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "    # train_point should be alpha_train_dataset[0], a tuple of image and label\n",
    "\n",
    "    w = w.clone().detach().requires_grad_(True)\n",
    "\n",
    "    divide1 = hidden_size*784\n",
    "    divide2 = divide1 + hidden_size\n",
    "    divide3 = divide2 + hidden_size*10\n",
    "\n",
    "    out1 = F.linear(train_point[0].reshape(-1, 784).to(device), w[:divide1].reshape(hidden_size,784), w[divide1:divide2])\n",
    "    out2 = F.relu(out1)\n",
    "    out3 = F.linear(out2, w[divide2:divide3].reshape(10,hidden_size), w[divide3:])\n",
    "    print(out3)\n",
    "    loss = criterion(out3, torch.tensor([train_point[1]]).to(device))\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    for p in classification_model.parameters():\n",
    "        p.grad = None\n",
    "    return w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f7725d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.5083,  5.2741,  0.5708, -0.1582, -0.4546, -0.0932,  0.7715,  0.6345,\n",
      "          0.1679, -0.3296]], grad_fn=<AddmmBackward0>)\n",
      "tensor(0.0507, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0022, -0.0022, -0.0022,  ...,  0.0092,  0.0058,  0.0035])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = loss_grad_at_point(torch.cat(tuple([_.view(-1) for _ in classification_model.parameters()])), [x_dev, y_dev])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "636afb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a != b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569beff",
   "metadata": {},
   "source": [
    "# they are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "317a97f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9000, -8.1000,  0.9000,  0.9000,  0.9000,  0.9000,  0.9000,  0.9000,\n",
       "          0.9000,  0.9000]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[np.argwhere(a != b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f5cb3f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0022, -0.0022, -0.0022,  ...,  0.0092,  0.0058,  0.0035]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[np.argwhere(a != b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1d33d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST_1(\n",
       "  (l1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (l2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1de34ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([32, 784]),\n",
       " torch.Size([32]),\n",
       " torch.Size([10, 32]),\n",
       " torch.Size([10])]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in list(classification_model.parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c5880b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0513, -0.0209,  0.1288, -0.0991,  0.0932, -0.0194, -0.0962, -0.0468,\n",
       "         0.1214,  0.0078], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(tuple([_.view(-1) for _ in classification_model.parameters()]))[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09893445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
