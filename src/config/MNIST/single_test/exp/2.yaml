exp_title: original_config
dataset_name: mnist
train_classes: ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]
num_per_class: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]
classification_model: MNIST_LogisticRegression
influence_model: hashmap_IF
max_epoch: 300
influence_lr: 0.3
influence_momentum: 0.9
influence_weight_decay: 0.01
classification_lr: 0.3
classification_momentum: 0.9
classification_weight_decay: 0.01
batch_size: 32
_hidden_size_classification: 32
_hidden_size_influence: 32
dataWeight_weight_decay: 1
dataWeight_weight_init: 0.
softmax_temp: 10
train_classification_till_converge: False
use_pretrain_classification: True
reset_pretrain_classification_every_epoch: False
dev_id_num: 9
dev_original_folder: data/MNIST/dev/oneClassEach/original_sampled
dev_transformed_folder: data/MNIST/dev/oneClassEach/transformed_sampled
test_original_folder: ""
test_transformed_folder: ""
_gpu_id: 0
_ckpt_dir: checkpoints/fenchel/mnist

seed: 1
_pretrain_ckpt_name: first1000.pt #modify together

_num_class: 10 # the maximum number of class
_ckpt_name: last
