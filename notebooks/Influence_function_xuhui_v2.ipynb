{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFxE-wjQAjzJ"
   },
   "source": [
    "# IF on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SLpy25HXAqml"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaochen/anaconda3/envs/IFv2/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/xiaochen/anaconda3/envs/IFv2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import scatter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "from torch.autograd.functional import hessian\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iszzRiJ7MC-q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd.functional import hessian\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import scatter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMMPQJ0NLwkl"
   },
   "source": [
    "## Hessian on MOG with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lQVlGa9H9PD6"
   },
   "outputs": [],
   "source": [
    "num_train = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "1FIdsu2QA6Ot",
    "outputId": "5cd3872c-2ac7-410c-f65f-adbfe3bb4b6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0e3829d610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx = np.array([0, 1])\n",
    "yy = np.array([0, 1])\n",
    "means = [xx.mean(), yy.mean()]  \n",
    "stds = [xx.std()/3, yy.std()/3]\n",
    "corr = 0.7         # correlation\n",
    "covs = [[stds[0]**2          , stds[0]*stds[1]*corr], \n",
    "        [stds[0]*stds[1]*corr,           stds[1]**2]] \n",
    "\n",
    "m = np.random.multivariate_normal(means, covs, num_train).T\n",
    "scatter(m[0], m[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRVzYmrGCsGu",
    "outputId": "893cdc46-9130-4213-ba8d-3fc9393d53fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15706138173258988, 0.5211235134013863)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1, y_1 = m.T[0]\n",
    "x_1, y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "v3k3NdMaBkB9"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(np.array([m.T[:,0]]).T, m.T[:,1])\n",
    "\n",
    "k, b = model.coef_[0], model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAtCA2wjBoik",
    "outputId": "c00956c0-6106-48e5-a5af-fe013fc9db40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7303], dtype=torch.float64, requires_grad=True),\n",
       " tensor([0.1280], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.tensor([k], requires_grad=True)\n",
    "b = torch.tensor([b], requires_grad=True)\n",
    "k, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XniNC4SBC7Bg",
    "outputId": "1a572428-a166-42c4-c901-b5515c8f135e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7303, 0.1280], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor([k, b])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9sHR4NaQKOVg"
   },
   "outputs": [],
   "source": [
    "def parent_mse_loss(w, x, y):\n",
    "    def MSE_loss(w):\n",
    "        return (torch.dot(w,torch.tensor([x, 1]))-y)**2\n",
    "    return MSE_loss\n",
    "\n",
    "def MSE_loss(w):\n",
    "    return (torch.matmul(w[:2].reshape(-1,2),torch.tensor([x_1, 1]).reshape(2,1))-y_1)**2\n",
    "\n",
    "def MSE_loss_all(w):\n",
    "    Loss = 0\n",
    "    for i in range(num_train):\n",
    "        Loss = Loss + (torch.dot(w,torch.tensor([m.T[i][0], 1]))-m.T[i][1])**2\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3HuMU1QvE-df"
   },
   "outputs": [],
   "source": [
    "def CE_loss_test(w):\n",
    "\n",
    "    divide1 = 4\n",
    "    \n",
    "    images = torch.tensor([[1.0,1.0]])\n",
    "\n",
    "    labels = torch.tensor([0])\n",
    "\n",
    "    #out1 = F.linear(images.reshape(-1, 784).to(device), w[:divide1].reshape(2,784), w[divide1:])\n",
    "\n",
    "\n",
    "    mat1 = images.reshape(-1,2)\n",
    "\n",
    "    mat2 = w[:divide1].reshape(2,2).t()\n",
    "    \n",
    "    out1 = w[divide1:].reshape(1,2) + torch.matmul(mat1, mat2) \n",
    "    loss = criterion(out1, labels)\n",
    "\n",
    "    #loss = out1\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_75FnzOGV_t",
    "outputId": "2d8a1e23-370d-43be-ff3b-e4de1d371ce4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divide1 = 4\n",
    "w = torch.tensor([2.0,2.0,2.0,2.0,2.0,2.0])\n",
    "images = torch.tensor([[1.0,1.0]])\n",
    "mat1 = images.reshape(-1,2)\n",
    "mat2 = w[:divide1].reshape(2,2).t()\n",
    "#torch.matmul(mat1, mat2)\n",
    "out1 = w[divide1:].reshape(1,2) + torch.matmul(mat1, mat2) \n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bjn1ofVaFrhx",
    "outputId": "29bf1e17-5f6a-435f-c891-53c357075e26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6931)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor([2.0,2.0,2.0,2.0,2.0,2.0])\n",
    "CE_loss_test(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhR-8f_j_v3P",
    "outputId": "ecb400ba-2977-469e-e0cd-723bf602c3dc"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMSE_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mMSE_loss\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mMSE_loss\u001b[39m(w):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39my_1)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "MSE_loss(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfsWYzEOJgT8",
    "outputId": "77704fb1-3fa7-4e6a-c4cb-b541fac0bb1a"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot : expected both vectors to have same dtype, but found Float and Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m Hessian \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_train):\n\u001b[0;32m----> 3\u001b[0m     Hessian \u001b[38;5;241m=\u001b[39m Hessian \u001b[38;5;241m+\u001b[39m \u001b[43mhessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_mse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m Hessian\u001b[38;5;241m/\u001b[39mnum_train\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:808\u001b[0m, in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[1;32m    805\u001b[0m     _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jac\n\u001b[0;32m--> 808\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m               \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_jacobian_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:575\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    572\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    573\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 575\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[1;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:804\u001b[0m, in \u001b[0;36mhessian.<locals>.jac_func\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_jacobian_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-mode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;66;03m# _grad_preprocess requires create_graph=True and input to require_grad\u001b[39;00m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# or else the input will be detached\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inp)\n\u001b[0;32m--> 804\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_single_output_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:575\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    572\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    573\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 575\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[1;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:787\u001b[0m, in \u001b[0;36mhessian.<locals>.ensure_single_output_function\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mensure_single_output_function\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m--> 787\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m     is_out_tuple, t_out \u001b[38;5;241m=\u001b[39m _as_tuple(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhessian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    789\u001b[0m     _check_requires_grad(t_out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mparent_mse_loss.<locals>.MSE_loss\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mMSE_loss\u001b[39m(w):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39my)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot : expected both vectors to have same dtype, but found Float and Double"
     ]
    }
   ],
   "source": [
    "Hessian = torch.zeros([2,2])\n",
    "for i in range(num_train):\n",
    "    Hessian = Hessian + hessian(parent_mse_loss(w, m.T[i][0], m.T[i][1]), w)\n",
    "Hessian/num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIgFsJAe3Pta",
    "outputId": "f1cc0fe3-6403-42f2-8f74-f4997e0833aa"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot : expected both vectors to have same dtype, but found Float and Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhessian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMSE_loss_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mnum_train\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:808\u001b[0m, in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, outer_jacobian_strategy)\u001b[0m\n\u001b[1;32m    805\u001b[0m     _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jac\n\u001b[0;32m--> 808\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectorize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m               \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_jacobian_strategy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tuple_postprocess(res, (is_inputs_tuple, is_inputs_tuple))\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:575\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    572\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    573\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 575\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[1;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:804\u001b[0m, in \u001b[0;36mhessian.<locals>.jac_func\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outer_jacobian_strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward-mode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;66;03m# _grad_preprocess requires create_graph=True and input to require_grad\u001b[39;00m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# or else the input will be detached\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(t\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inp)\n\u001b[0;32m--> 804\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensure_single_output_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m _check_requires_grad(jac, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jac\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:575\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    572\u001b[0m is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    573\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _grad_preprocess(inputs, create_graph\u001b[38;5;241m=\u001b[39mcreate_graph, need_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 575\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m is_outputs_tuple, outputs \u001b[38;5;241m=\u001b[39m _as_tuple(outputs,\n\u001b[1;32m    577\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m                                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacobian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m _check_requires_grad(outputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "File \u001b[0;32m~/anaconda3/envs/IFv2/lib/python3.8/site-packages/torch/autograd/functional.py:787\u001b[0m, in \u001b[0;36mhessian.<locals>.ensure_single_output_function\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mensure_single_output_function\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m--> 787\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m     is_out_tuple, t_out \u001b[38;5;241m=\u001b[39m _as_tuple(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs of the user-provided function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhessian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    789\u001b[0m     _check_requires_grad(t_out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, strict\u001b[38;5;241m=\u001b[39mstrict)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mMSE_loss_all\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m     10\u001b[0m Loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_train):\n\u001b[0;32m---> 12\u001b[0m     Loss \u001b[38;5;241m=\u001b[39m Loss \u001b[38;5;241m+\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39mm\u001b[38;5;241m.\u001b[39mT[i][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Loss\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot : expected both vectors to have same dtype, but found Float and Double"
     ]
    }
   ],
   "source": [
    "hessian(MSE_loss_all, w)/num_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EirtzWVFL0l0"
   },
   "source": [
    "## Hessian on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d6uUU5rMMQQ"
   },
   "source": [
    "### Set up before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9UvFQaZDL7DZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 63452281.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 54812531.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 70908219.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 14586928.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pWKGSTXtMWBX"
   },
   "outputs": [],
   "source": [
    "input_size = 784 # 28*28\n",
    "hidden_size = 32\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 100 #100\n",
    "learning_rate = 0.001\n",
    "\n",
    "training_size = 60000\n",
    "testing_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bPxms_lUMtod"
   },
   "outputs": [],
   "source": [
    "np.random.seed(35)\n",
    "training_selector = np.random.choice(range(60000), replace = False, size = training_size)\n",
    "testing_selector = np.random.choice(range(10000), replace = False, size = testing_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LJf3HBsLMz8F"
   },
   "outputs": [],
   "source": [
    "class Alpha_Train_Dataset(Dataset):\n",
    "  def __init__(self):\n",
    "      \n",
    "      self.x = train_dataset.data[training_selector].float()\n",
    "      self.y = train_dataset.targets[training_selector]\n",
    "      \n",
    "      #self.n_samples = int(train_dataset.data.shape[0]*alpha)\n",
    "      self.n_samples = len(training_selector)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      return self.x[index], self.y[index]\n",
    "  def __len__(self):\n",
    "      return self.n_samples\n",
    "\n",
    "class Alpha_Test_Dataset(Dataset):\n",
    "  def __init__(self):\n",
    "      \n",
    "      self.x = test_dataset.data[testing_selector].float()#[random_selector].float()\n",
    "      self.y = test_dataset.targets[testing_selector]#[random_selector]\n",
    "      \n",
    "      self.n_samples = len(testing_selector)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      return self.x[index], self.y[index]\n",
    "  def __len__(self):\n",
    "      return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wdKO3dm6NKbX"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "    super(NeuralNet, self).__init__()\n",
    "    self.l1 = nn.Linear(input_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.l1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.l2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CXudkreNaa_"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FnCXlVVCNlrb"
   },
   "outputs": [],
   "source": [
    "alpha_train_dataset = Alpha_Train_Dataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=alpha_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        #images = images.reshape(-1, 28*28).to(device) # can change -1 to 100\n",
    "        images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "alpha_test_dataset = Alpha_Test_Dataset()\n",
    "test_loader = torch.utils.data.DataLoader(dataset=alpha_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        # 把一个batch reshape 成一个 100 by 784 的 vector 来做prediction\n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        # value, index\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    acc = 100 * n_correct/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FWmYk9WxwRtx",
    "outputId": "7b975229-5331-4be5-c151-9f5df932775b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oj4s7_U3PpNy"
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     out = model(alpha_train_dataset[0][0].reshape(-1, 784).to(device))\n",
    "#     loss = criterion(out, torch.tensor([alpha_train_dataset[0][1]]))\n",
    "#     print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIaZsTl3FKSm"
   },
   "source": [
    "### Calculate Hessian on numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "s1NeaPNLT81M"
   },
   "outputs": [],
   "source": [
    "def CE_loss(w_1, b_1, w_2, b_2):\n",
    "    out1 = F.linear(alpha_train_dataset[1][0].reshape(-1, 784).to(device), w_1.reshape(hidden_size,784), b_1)\n",
    "    out2 = F.relu(out1)\n",
    "    out3 = F.linear(out2, w_2.reshape(10,hidden_size), b_2)\n",
    "    loss = criterion(out3, torch.tensor([alpha_train_dataset[1][1]]).to(device))\n",
    "    return loss\n",
    "\n",
    "def CE_loss_new(w):\n",
    "    divide1 = hidden_size*784\n",
    "    divide2 = divide1 + hidden_size\n",
    "    divide3 = divide2 + hidden_size*10\n",
    "    out1 = F.linear(alpha_train_dataset[2][0].reshape(-1, 784).to(device), w[:divide1].reshape(hidden_size,784), w[divide1:divide2])\n",
    "    out2 = F.relu(out1)\n",
    "    out3 = F.linear(out2, w[divide2:divide3].reshape(10,hidden_size), w[divide3:])\n",
    "    loss = criterion(out3, torch.tensor([alpha_train_dataset[2][1]]).to(device))\n",
    "    return loss\n",
    "\n",
    "def CE_loss_new_all(w):\n",
    "    divide1 = hidden_size*784\n",
    "    divide2 = divide1 + hidden_size\n",
    "    divide3 = divide2 + hidden_size*10\n",
    "\n",
    "    Loss = []\n",
    "    for i in range(training_size):\n",
    "        out1 = F.linear(alpha_train_dataset[i][0].reshape(-1, 784).to(device), w[:divide1].reshape(hidden_size,784), w[divide1:divide2])\n",
    "        out2 = F.relu(out1)\n",
    "        out3 = F.linear(out2, w[divide2:divide3].reshape(10,hidden_size), w[divide3:])\n",
    "        loss = criterion(out3, torch.tensor([alpha_train_dataset[i][1]]).to(device))\n",
    "        Loss.append(loss)\n",
    "    return sum(Loss)\n",
    "\n",
    "def CE_loss_new_all2(w):\n",
    "    divide1 = hidden_size*784\n",
    "    divide2 = divide1 + hidden_size\n",
    "    divide3 = divide2 + hidden_size*10\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=alpha_train_dataset, batch_size=training_size, shuffle=False)\n",
    "    examples = iter(train_loader)\n",
    "    images, labels = examples.next()\n",
    "    images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "\n",
    "    out1 = F.linear(images, w[:divide1].reshape(hidden_size,784), w[divide1:divide2])\n",
    "    out2 = F.relu(out1)\n",
    "    out3 = F.linear(out2, w[divide2:divide3].reshape(10,hidden_size), w[divide3:])\n",
    "    loss = criterion(out3, labels.to(device))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZkhgwZiYy8x"
   },
   "outputs": [],
   "source": [
    "#w_1, b_1, w_2, b_2 = list(model.parameters())\n",
    "#w_1, b_1, w_2, b_2 = [_.view(-1) for _ in model.parameters()]\n",
    "#CE_loss(w_1, b_1, w_2, b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIqemlTD0F_g"
   },
   "outputs": [],
   "source": [
    "# w = torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "# CE_loss_new_all2(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWILjjYkqv1a"
   },
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "#    H = hessian(CE_loss, tuple([_.view(-1) for _ in model.parameters()]))\n",
    "with torch.no_grad():\n",
    "   Hessian = hessian(CE_loss_new_all2, torch.cat(tuple([_.view(-1) for _ in model.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btfZd7JS07ie"
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#    Hessian = hessian(CE_loss_new, torch.cat(tuple([_.view(-1) for _ in model.parameters()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIgNAYrhKObS"
   },
   "outputs": [],
   "source": [
    "np_Hessian = Hessian.to(\"cpu\").numpy()/training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K88RBFXt-u8i",
    "outputId": "e5c61a78-b5cb-45e0-e912-d84c69cba58b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.  , 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.01, 0.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.01, ..., 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [0.  , 0.  , 0.  , ..., 0.01, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.01, 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 0.  , 0.01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damping_matrix = np.diag(np.full(Hessian.shape[0],0.01),0)\n",
    "damping_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAdohm0u0IDk"
   },
   "outputs": [],
   "source": [
    "damping_hessian = np_Hessian + damping_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyO1MVd8eGrf"
   },
   "source": [
    "#### Save hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrbZfQXL7h2b",
    "outputId": "28ff27ad-07e4-4bf9-c0fe-b2f6d1aee02b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twnXfEjoMkUS"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMf5UYoK7qDZ"
   },
   "outputs": [],
   "source": [
    "np.save(\"/content/gdrive/MyDrive/hessian_damping_32_hiddensize\", damping_hessian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSgli-9oeH4-"
   },
   "source": [
    "#### Save model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rf1cJO-IdmE_"
   },
   "outputs": [],
   "source": [
    "w = torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "np_w = w.to(\"cpu\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6D1QYMAheJT2"
   },
   "outputs": [],
   "source": [
    "np.save(\"/content/gdrive/MyDrive/model_weight_32_hiddensize\", np_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzjV0IcKe4Bw"
   },
   "source": [
    "#### Load hessian and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7bQUQCG9dLo"
   },
   "outputs": [],
   "source": [
    "np_Hessian = np.load(\"/content/gdrive/MyDrive/hessian_damping_32_hiddensize.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqyRvqB9e9Nq"
   },
   "outputs": [],
   "source": [
    "np_w = np.load(\"/content/gdrive/MyDrive/model_weight_32_hiddensize.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQw7OZKECBon"
   },
   "outputs": [],
   "source": [
    "inv_hessian = np.linalg.inv(np_Hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yV78qj6nD-jG"
   },
   "outputs": [],
   "source": [
    "np.save(\"/content/gdrive/MyDrive/hessian_damping_inverse_32_hiddensize\", inv_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fc-yfXaQ1Jjk"
   },
   "outputs": [],
   "source": [
    "inv_hessian = np.load(\"/content/gdrive/MyDrive/hessian_damping_inverse_32_hiddensize.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPefaYkMM_P-",
    "outputId": "b730a182-f331-4cf1-91cb-4182d6b8e57b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.00000000e+00,  2.84550131e-22,  5.95570041e-23],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         5.62482817e-23,  1.00000000e+00,  1.19114008e-22],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -3.41129285e-21, -6.70016296e-22,  1.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np_Hessian, inv_hessian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZKFV95OhFx8"
   },
   "source": [
    "### Calculate Hessian on torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZASf03HohMsd"
   },
   "outputs": [],
   "source": [
    "def CE_loss_new_all2(w):\n",
    "    divide1 = hidden_size*784\n",
    "    divide2 = divide1 + hidden_size\n",
    "    divide3 = divide2 + hidden_size*10\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=alpha_train_dataset, batch_size=training_size, shuffle=False)\n",
    "    examples = iter(train_loader)\n",
    "    images, labels = examples.next()\n",
    "\n",
    "    images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "\n",
    "    out1 = F.linear(images, w[:divide1].reshape(hidden_size,784), w[divide1:divide2])\n",
    "    out2 = F.relu(out1)\n",
    "    out3 = F.linear(out2, w[divide2:divide3].reshape(10,hidden_size), w[divide3:])\n",
    "    loss = criterion(out3, labels.to(device))*training_size\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yVTM7510hXgv"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "   Hessian = hessian(CE_loss_new_all2, torch.cat(tuple([_.view(-1) for _ in model.parameters()])))/training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnSGhUXNcSfU"
   },
   "outputs": [],
   "source": [
    "damping_matrix = torch.tensor(np.diag(np.full(Hessian.shape[0],0.001),0)).to(device)\n",
    "damping_hessian = Hessian + damping_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPJPmiB-eMru"
   },
   "outputs": [],
   "source": [
    "inv_hessian = torch.linalg.inv(damping_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tlZTrOLeXa2"
   },
   "outputs": [],
   "source": [
    "w = torch.cat(tuple([_.view(-1) for _ in model.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUgBl19jcTQ4"
   },
   "source": [
    "### Save and reload to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOC_I5E7aCPo",
    "outputId": "2310f233-c9b1-4ace-ae22-fd732d38f633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6RqRjX28aHcq"
   },
   "outputs": [],
   "source": [
    "np_damping_hessian = damping_hessian.to(\"cpu\").numpy()\n",
    "\n",
    "np.save(\"/content/gdrive/MyDrive/hessian_damping_32_hiddensize\", np_damping_hessian)\n",
    "\n",
    "w = torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "np_w = w.to(\"cpu\").detach().numpy()\n",
    "np.save(\"/content/gdrive/MyDrive/model_weight_32_hiddensize\", np_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4SCToLOTat-H"
   },
   "outputs": [],
   "source": [
    "np_Hessian = np.load(\"/content/gdrive/MyDrive/hessian_damping_32_hiddensize.npy\")\n",
    "np_w = np.load(\"/content/gdrive/MyDrive/model_weight_32_hiddensize.npy\")\n",
    "damping_hessian = torch.from_numpy(np_Hessian).to(device)\n",
    "w = torch.from_numpy(np_w).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "PN0VUVM2hpnh",
    "outputId": "95b5952d-e2ac-4b58-8c18-32fe4874b442"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-34e28d7b05d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#damping_matrix = torch.tensor(np.diag(np.full(Hessian.shape[0],0.001),0)).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#damping_hessian = Hessian + damping_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minv_hessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdamping_hessian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.83 GiB (GPU 0; 15.90 GiB total capacity; 14.48 GiB already allocated; 655.75 MiB free; 14.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#damping_matrix = torch.tensor(np.diag(np.full(Hessian.shape[0],0.001),0)).to(device)\n",
    "#damping_hessian = Hessian + damping_matrix\n",
    "inv_hessian = torch.linalg.inv(damping_hessian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RovowtXlcYWQ"
   },
   "source": [
    "### Calculate IF for alpha train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhDEfyHkhqWY"
   },
   "outputs": [],
   "source": [
    "target_example = alpha_test_dataset[10][0] # it's a 9\n",
    "plt.imshow(target_example, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9H2aXJJhs9R"
   },
   "outputs": [],
   "source": [
    "def loss_grad_at_point(w, train_point):\n",
    "    # w should be torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "    # train_point should be alpha_train_dataset[0], a tuple of image and label\n",
    "\n",
    "    w = w.clone().detach().requires_grad_(True)\n",
    "\n",
    "    divide = 10*784\n",
    "\n",
    "    out = F.linear(train_point[0].reshape(-1, 784).to(device), w[:divide].reshape(10,784), w[divide:])\n",
    "\n",
    "    loss = criterion(out, torch.tensor([train_point[1]]).to(device))\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    return w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yl_CycWQhx8o"
   },
   "outputs": [],
   "source": [
    "#w = torch.cat(tuple([_.view(-1) for _ in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wFkh0fPhx_J"
   },
   "outputs": [],
   "source": [
    "def calculate_if(train_point, test_point, inv_Hessian):\n",
    "    # test point should be alpha_test_dataset[10]\n",
    "\n",
    "    test_loss = loss_grad_at_point(w, test_point)\n",
    "\n",
    "    train_loss = loss_grad_at_point(w, train_point)\n",
    "\n",
    "    if_score = -torch.matmul(torch.matmul(test_loss.t().double(), inv_Hessian), train_loss.double())\n",
    "\n",
    "    return if_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Em3ZzSbrhyCH"
   },
   "outputs": [],
   "source": [
    "if_score_list = []\n",
    "for i in range(training_size):\n",
    "    if_score = calculate_if(alpha_train_dataset[i], alpha_test_dataset[10], inv_hessian)\n",
    "    if_score_list.append(if_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pq9CEazwh21x"
   },
   "outputs": [],
   "source": [
    "if_score_series = pd.Series(if_score_list)\n",
    "if_score_series_sorted = if_score_series.sort_values(ascending = False)\n",
    "if_score_series_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQgSuEfhh24p"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "axs[0][0].imshow(alpha_train_dataset[3853][0], cmap = \"gray\")\n",
    "axs[0][1].imshow(alpha_train_dataset[1949][0], cmap = \"gray\")\n",
    "axs[0][2].imshow(alpha_train_dataset[3209][0], cmap = \"gray\")\n",
    "axs[1][0].imshow(alpha_train_dataset[624][0], cmap = \"gray\")\n",
    "axs[1][1].imshow(alpha_train_dataset[1650][0], cmap = \"gray\")\n",
    "axs[1][2].imshow(alpha_train_dataset[5446][0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYiIwDPSFvz2"
   },
   "source": [
    "### Calculate IF on ordered dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYVnDC2ZUGHO"
   },
   "source": [
    "test point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uR70_ZLdf77H"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "-y6360DjTvl1",
    "outputId": "f6da6567-9509-4f71-eb92-ca26ee929a0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f048801e410>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#target_example = alpha_test_dataset[10][0] # it's a 9\n",
    "#plt.imshow(target_example, cmap = \"gray\")\n",
    "plt.imshow(test_dataset.data[12], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJorcZOX18tz"
   },
   "outputs": [],
   "source": [
    "test_point = (test_dataset.data[12].float(), test_dataset.targets[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4swSRrBE4um"
   },
   "outputs": [],
   "source": [
    "def loss_grad_at_point(w, train_point):\n",
    "    # w should be torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "    # train_point should be alpha_train_dataset[0], a tuple of image and label\n",
    "\n",
    "    w = w.clone().detach().requires_grad_(True)\n",
    "\n",
    "    divide1 = hidden_size*784\n",
    "    divide2 = divide1 + hidden_size\n",
    "    divide3 = divide2 + hidden_size*10\n",
    "\n",
    "    images = ((train_point[0].reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "\n",
    "    out1 = F.linear(images, w[:divide1].reshape(hidden_size,784), w[divide1:divide2])\n",
    "    out2 = F.relu(out1)\n",
    "    out3 = F.linear(out2, w[divide2:divide3].reshape(10,hidden_size), w[divide3:])\n",
    "\n",
    "    loss = criterion(out3, torch.tensor([train_point[1]]).to(device))\n",
    "    loss.backward()\n",
    "\n",
    "    return w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-0e4Hm2fI_Z"
   },
   "outputs": [],
   "source": [
    "#w = torch.tensor(np_w).to(device)\n",
    "#inv_hessian = torch.tensor(inv_hessian).to(device).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAVaKP3HWiri"
   },
   "source": [
    "### Calculate if score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzsnT5MeVpUp"
   },
   "outputs": [],
   "source": [
    "def calculate_if(train_point, test_point, inv_Hessian):\n",
    "    # test point should be alpha_test_dataset[10]\n",
    "\n",
    "    test_loss = loss_grad_at_point(w, test_point)#.to(\"cpu\").numpy()\n",
    "\n",
    "    train_loss = loss_grad_at_point(w, train_point)#.to(\"cpu\").numpy()\n",
    "\n",
    "    if_score = -torch.matmul(torch.matmul(test_loss.t(), inv_Hessian), train_loss)\n",
    "\n",
    "    return if_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rMsj4pgi3E1"
   },
   "outputs": [],
   "source": [
    "test_point = (test_dataset.data[12].float(), test_dataset.targets[12])\n",
    "if_score_list = []\n",
    "for i in range(training_size):\n",
    "    train_point = (train_dataset.data[i].float(), train_dataset.targets[i])\n",
    "    if_score = calculate_if(train_point, test_point, inv_hessian)\n",
    "    if_score_list.append(if_score)\n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"{i+1}/60000 complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJJD_dHzGjIB",
    "outputId": "857fdf1c-93d0-4c29-ed1d-333c282b4c82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(if_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkZeYRSgmGdT"
   },
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMYI1zpfmIb8"
   },
   "outputs": [],
   "source": [
    "if_score_series = pd.Series(torch.tensor(if_score_list).to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fh_XQKGrmIej"
   },
   "outputs": [],
   "source": [
    "if_score_series_sorted = if_score_series.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLFSrTw7mXAF",
    "outputId": "fd3480b7-7de1-448d-d42d-c97f20dc8149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36907    2883.714111\n",
       "12028    2265.501465\n",
       "26778    2208.476074\n",
       "45238    2163.090088\n",
       "1244     2130.077881\n",
       "            ...     \n",
       "18118   -1945.744263\n",
       "6156    -1973.395874\n",
       "31840   -2066.142334\n",
       "51248   -2464.245605\n",
       "14582   -3051.974854\n",
       "Length: 60000, dtype: float32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_score_series_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxAzhUNvqlK_"
   },
   "outputs": [],
   "source": [
    "np.save(\"/content/gdrive/MyDrive/if_scores_32_hiddensize\", torch.tensor(if_score_list).to(\"cpu\").numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_FNNWuGqXGg"
   },
   "source": [
    "#### Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "fKDNCL_lmbxl",
    "outputId": "80812712-0d04-4ef8-b6b7-28a726b55de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f04826133d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_dataset.data[12], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7r75nKPqu1Ie",
    "outputId": "1be814e6-6237-4c09-80c2-24377f4744c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_train_dataset[47085][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "SybIVWU4qBwf",
    "outputId": "e5fc6512-2c5f-4c4b-eaa2-0654501c38d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0482707250>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "axs[0][0].imshow(train_dataset.data[36907], cmap = \"gray\")\n",
    "axs[0][1].imshow(train_dataset.data[12028], cmap = \"gray\")\n",
    "axs[0][2].imshow(train_dataset.data[26778], cmap = \"gray\")\n",
    "axs[1][0].imshow(train_dataset.data[14582], cmap = \"gray\")\n",
    "axs[1][1].imshow(train_dataset.data[51248], cmap = \"gray\")\n",
    "axs[1][2].imshow(train_dataset.data[31840], cmap = \"gray\")\n",
    "#alpha_train_dataset[if_score_series_sorted.index[-1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cbo_ZRI0JNKH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6nnnFs5CvmG"
   },
   "source": [
    "# IF vs LOOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0mSD5v0D015"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import scatter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeXVTeJ1LZpJ"
   },
   "outputs": [],
   "source": [
    "if_score_list = np.load(\"/content/gdrive/MyDrive/if_scores_32_hiddensize.npy\")\n",
    "if_score_series = pd.Series(if_score_list)\n",
    "if_score_series_sorted = if_score_series.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_eti9Q4LsLg"
   },
   "outputs": [],
   "source": [
    "idx_to_remove = np.array(if_score_series_sorted.apply(lambda x: abs(x)).sort_values(ascending = False).index[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vFsRI19MOC-"
   },
   "outputs": [],
   "source": [
    "diff_in_loss_by_if = np.array(if_score_series[idx_to_remove]/(-60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xrf1T6HwCxXC",
    "outputId": "ea1267fd-a148-4944-86ac-0c864e63475e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14582, 36907, 51248, 12028, 26778, 45238,  1244, 13850, 31840,\n",
       "       47600,  6156, 18118, 46384, 32342, 24756, 20211, 49547, 27292,\n",
       "       13350, 51125, 56220, 15741, 55730, 29929, 46643, 20652,  5821,\n",
       "       16992, 22722, 45761,  8268, 48786, 25806, 53528, 43658, 37248,\n",
       "       32391, 45749, 50329, 20600,  1854, 24719,   148,  8468,  5559,\n",
       "       27180, 56268, 47227, 48522, 31428])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STPxWs_NDu_e"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transforms.ToTensor(), download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transforms.ToTensor(), download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNynRavrDjhQ"
   },
   "outputs": [],
   "source": [
    "input_size = 784 # 28*28\n",
    "hidden_size = 32\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 100 #100\n",
    "learning_rate = 0.001\n",
    "\n",
    "training_size = 60000\n",
    "testing_size = 1000\n",
    "\n",
    "testing_selector = np.random.choice(range(10000), replace = False, size = testing_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eFSaTA8DNIe"
   },
   "outputs": [],
   "source": [
    "class One_Out_Train_Dataset(Dataset):\n",
    "  def __init__(self, training_selector):\n",
    "      \n",
    "      self.x = train_dataset.data[training_selector].float()\n",
    "      self.y = train_dataset.targets[training_selector]\n",
    "      \n",
    "      #self.n_samples = int(train_dataset.data.shape[0]*alpha)\n",
    "      self.n_samples = len(training_selector)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      return self.x[index], self.y[index]\n",
    "  def __len__(self):\n",
    "      return self.n_samples\n",
    "\n",
    "class Alpha_Test_Dataset(Dataset):\n",
    "  def __init__(self):\n",
    "      \n",
    "      self.x = test_dataset.data[testing_selector].float()#[random_selector].float()\n",
    "      self.y = test_dataset.targets[testing_selector]#[random_selector]\n",
    "      \n",
    "      self.n_samples = len(testing_selector)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      return self.x[index], self.y[index]\n",
    "  def __len__(self):\n",
    "      return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cv5i3U_KHFrc"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "    super(NeuralNet, self).__init__()\n",
    "    self.l1 = nn.Linear(input_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.l1(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.l2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPZYRGbRH10t"
   },
   "outputs": [],
   "source": [
    "test_point = (test_dataset.data[12].float(), test_dataset.targets[12])\n",
    "test_image = test_point[0].reshape(-1, 28*28).to(device)\n",
    "test_label = torch.tensor([test_point[1]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCZrSj6yKs8e"
   },
   "outputs": [],
   "source": [
    "original_test_loss = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_WWcNZtD7QO"
   },
   "outputs": [],
   "source": [
    "change_in_loss_lst = []\n",
    "counter = 1\n",
    "for idx in idx_to_remove:\n",
    "    training_selector = np.concatenate((np.arange(0,idx), np.arange(idx+1,60000)))\n",
    "\n",
    "    alpha_train_dataset = One_Out_Train_Dataset(training_selector)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=alpha_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # 100, 1, 28, 28\n",
    "            images = images.reshape(-1, 28*28).to(device) # can change -1 to 100\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_output = model(test_image)\n",
    "        test_loss = criterion(test_output, test_label)\n",
    "        change_in_loss_lst.append(test_loss.item() - original_test_loss)\n",
    "        counter = counter + 1\n",
    "        print(f\"{counter}/50 complete\")\n",
    "\n",
    "    # alpha_test_dataset = Alpha_Test_Dataset()\n",
    "    # test_loader = torch.utils.data.DataLoader(dataset=alpha_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     n_correct = 0\n",
    "    #     n_samples = 0\n",
    "    #     for images, labels in test_loader:\n",
    "    #         # 把一个batch reshape 成一个 100 by 784 的 vector 来做prediction\n",
    "    #         images = images.reshape(-1, 28*28).to(device)\n",
    "    #         labels = labels.to(device)\n",
    "    #         output = model(images)\n",
    "    #         # value, index\n",
    "    #         _, predictions = torch.max(output, 1)\n",
    "    #         n_samples += labels.shape[0]\n",
    "    #         n_correct += (predictions == labels).sum().item()\n",
    "    #     acc = 100 * n_correct/n_samples\n",
    "    #     print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztRLeHRdKiq1"
   },
   "source": [
    "#### calculate original test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9dhQI08HAS5"
   },
   "outputs": [],
   "source": [
    "def loss_at_point(w, train_point):\n",
    "    # w should be torch.cat(tuple([_.view(-1) for _ in model.parameters()]))\n",
    "    # train_point should be alpha_train_dataset[0], a tuple of image and label\n",
    "\n",
    "    w = w.clone().detach()\n",
    "\n",
    "    divide1 = hidden_size*784\n",
    "    divide2 = divide1 + hidden_size\n",
    "    divide3 = divide2 + hidden_size*10\n",
    "\n",
    "    out1 = F.linear(train_point[0].reshape(-1, 784).to(device), w[:divide1].reshape(hidden_size,784), w[divide1:divide2])\n",
    "    out2 = F.relu(out1)\n",
    "    out3 = F.linear(out2, w[divide2:divide3].reshape(10,hidden_size), w[divide3:])\n",
    "\n",
    "    loss = criterion(out3, torch.tensor([train_point[1]]).to(device))\n",
    "    \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZ-H-e0FKLs_",
    "outputId": "d03f03f1-b16f-4a45-9b00-c5bc8a3557ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0003, device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss_at_point(w, test_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lINSXXWwKn7O"
   },
   "source": [
    "#### end of test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "el7a-lo9KQSk"
   },
   "outputs": [],
   "source": [
    "change_in_loss_array = np.array([_.item() for _ in change_in_loss_lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "yuGw3nr7QF9J",
    "outputId": "753e6e4a-67cb-4875-e2e9-bc217c2429e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7c6ad93a10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWIUlEQVR4nO3df4zc9X3n8eeb9YYsF4klxEnxGmKnQY4gXGPdHuREK6Xkh8lVxS6hDbnoaula0ajHH0kVK6aJDkJzxanvjupEeyeryQlVVXBKUtcVOvlonPxx6EpZx0SW0zhxgBQvabIFjOTgENt53x/7XTIez+zO7HxnZmc/z4e0Yub7/czuZ77A5zXf9+cz329kJpKkcl007A5IkobLIJCkwhkEklQ4g0CSCmcQSFLh1gy7A8vxhje8ITds2DDsbkjSSDl06NA/Z+ba5u0jGQQbNmxgZmZm2N2QpJESEd9rtd3SkCQVziCQpMIZBJJUOINAkgpnEEhS4UZy1ZD6b9/hWXYfOMZzJ0+zbnKCHVs2sW3z1LC7JakPDAJdYN/hWe768hFOnzkHwOzJ09z15SMAhoG0Clka0gV2Hzj2aggsOH3mHLsPHBtSjyT1k0GgCzx38nRX2yWNNoNAF1g3OdHVdkmjzSDQBXZs2cTE+Nh52ybGx9ixZdOQeiSpn5ws1gUWJoRdNSSVwSBQS9s2TznwS4WwNCRJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwnnRuRa8X6+kkhgETbxfr6TS1FIaioibI+JYRByPiJ0t9l8cEXur/Y9HxIam/VdFxKmI+Hgd/emF9+uVVJqegyAixoA/Ad4PXAN8KCKuaWr2W8CLmflW4H7gs037/xvwv3vtSx28X6+k0tRxRnA9cDwzn8rMnwAPAVub2mwFHqwePwy8OyICICK2AU8DR2voS8+8X6+k0tQRBFPAsw3PT1TbWrbJzLPAS8DlEfE64BPAp5f6IxFxR0TMRMTM3NxcDd1uzfv1SirNsJeP3gPcn5mnlmqYmXsyczozp9euXdu3Dm3bPMV9t17H1OQEAUxNTnDfrdc5USxp1apj1dAscGXD8/XVtlZtTkTEGuBS4HngBuC2iPgjYBL4aUT8ODMfqKFfy+b9eiWVpI4geAK4OiI2Mj/g3w78u6Y2+4HtwP8DbgMOZmYCv7TQICLuAU4NOwQkqTQ9B0Fmno2IO4EDwBjw+cw8GhH3AjOZuR/4HPDnEXEceIH5sJAkrQAx/8F8tExPT+fMzMywuyFJIyUiDmXmdPP2YU8WS5KGzCCQpMJ5raEmXnBOUmkMggZecE5SiSwNNfCCc5JKVNwZwWKlHy84J6lERQXBUqWfdZMTzLYY9Ad1wTnnJyQNQ1GloaVKP8O84NxCSM2ePE3ys5Dad7j5ah2SVK+igmCp0s8wLzjn/ISkYSmqNNRJ6WdYF5xzfkLSsBR1RtDv0s++w7PcuOsgG3c+wo27DnZV1vGGOJKGpagzgoVP+v2YkP3UviP8xd/9IwtXbmqeiF5qInjHlk3nTWSDN8SRNBhFBQH0p/Sz7/DseSGwoLHGv9QX1foZUpK0GK8+WoMbdx1sOfcAELSfm5ianOCxnTf1uXeSNM+rj/bRYhO66yYnnAiWtKIZBDVoN6EbzNf+nQiWtJIVN0fQSq/f6G010RvAh9951au/Z5ATwX5DWVI3ig+COq44utRE7yAngr2CqqRuFT9Z3G6idyyCn2aO3Cfqdu/HiWlJ7SaLiz8jaDdhe64KyFH7RO3EtKRuFT9Z3MmE7Shd88eJaUndKj4IWl12opVR+UQ9zCuoShpNxZeGmidyL4p4tSzUaFifqLtdAeQ3lCV1q/jJ4mbNq25g/hP1oC5HvVL7Imn0+c3iDg3zngTNvEeBpEEopjTUTYllWPckaOYKoMX5xTmpHkUEwaC/ZFXXADXseyivZH5xTqpPEaWhQZZY6rz3sCuA2rNsJtWniCAYZImlzgFqJc1XrDSWzaT6FFEaGmSJpe4BaqXMV6w0ls2k+hRxRjDIEovf7B0My2ZSfWoJgoi4OSKORcTxiNjZYv/FEbG32v94RGyotr83Ig5FxJHqn325KtogSywOUINh2UyqT89fKIuIMeDbwHuBE8ATwIcy85sNbX4X+JeZ+ZGIuB34tcz8YERsBn6Qmc9FxNuBA5m55P/JK+1Wlc1c1ihpJern1UevB45n5lPVH3oI2Ap8s6HNVuCe6vHDwAMREZl5uKHNUWAiIi7OzFdq6NfQWNeXNErqKA1NAc82PD9RbWvZJjPPAi8Blze1+QDw9XYhEBF3RMRMRMzMzc3V0G1JEqyQyeKIuBb4LPA77dpk5p7MnM7M6bVr1w6uc5K0ytURBLPAlQ3P11fbWraJiDXApcDz1fP1wF8Bv5mZ362hP5KkLtQRBE8AV0fExoh4DXA7sL+pzX5ge/X4NuBgZmZETAKPADsz87Ea+iJJ6lLPQVDV/O8EDgD/AHwxM49GxL0RcUvV7HPA5RFxHPg9YGGJ6Z3AW4H/FBFPVj9v7LVPkqTOeT8CSSqE9yOQJLVkEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTC1RIEEXFzRByLiOMRsbPF/osjYm+1//GI2NCw765q+7GI2FJHfyRJnes5CCJiDPgT4P3ANcCHIuKapma/BbyYmW8F7gc+W732GuB24FrgZuBPq98nSRqQOs4IrgeOZ+ZTmfkT4CFga1ObrcCD1eOHgXdHRFTbH8rMVzLzaeB49fskSQNSRxBMAc82PD9RbWvZJjPPAi8Bl3f4WgAi4o6ImImImbm5uRq6LUmCEZoszsw9mTmdmdNr164ddnckadWoIwhmgSsbnq+vtrVsExFrgEuB5zt8rSSpj+oIgieAqyNiY0S8hvnJ3/1NbfYD26vHtwEHMzOr7bdXq4o2AlcDf19DnyRJHVrT6y/IzLMRcSdwABgDPp+ZRyPiXmAmM/cDnwP+PCKOAy8wHxZU7b4IfBM4C/zHzDzXa58kSZ2L+Q/mo2V6ejpnZmaG3Q1JGikRcSgzp5u3j8xksSSpPwwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVLiegiAiXh8Rj0bEd6p/Xtam3faqzXciYnu17ZKIeCQivhURRyNiVy99kSQtT69nBDuBr2Tm1cBXqufniYjXA3cDNwDXA3c3BMZ/ycy3AZuBGyPi/T32R5LUpV6DYCvwYPX4QWBbizZbgEcz84XMfBF4FLg5M1/OzK8CZOZPgK8D63vsjySpS70GwZsy8/vV438C3tSizRTwbMPzE9W2V0XEJPCrzJ9VtBQRd0TETETMzM3N9dZrSdKr1izVICL+Fvi5Frs+2fgkMzMistsORMQa4AvAf8/Mp9q1y8w9wB6A6enprv+OJKm1JYMgM9/Tbl9E/CAirsjM70fEFcAPWzSbBd7V8Hw98LWG53uA72TmH3fU4xGw7/Asuw8c47mTp1k3OcGOLZvYtnmq9tdIUh2WDIIl7Ae2A7uqf/51izYHgD9smCB+H3AXQER8BrgU+O0e+9GxVgMuUNsgvO/wLHd9+Qinz5wDYPbkae768hGAtr9zOa9Z6j0ZIpI6FZnLr7JExOXAF4GrgO8Bv5GZL0TENPCRzPztqt1/AH6/etl/zsz/FRHrmZ87+BbwSrXvgcz8s6X+7vT0dM7MzHTd3+YBF2D8ooCAM+d+dhwmxse479brljWY3rjrILMnT1+wfWpygsd23lTbaxa0ek+99H+YDDSpvyLiUGZON2/v6YwgM58H3t1i+wwNn/Iz8/PA55vanACil7/frd0Hjp03YAKc+emFQXj6zDk+uvdJdh841nVZp12sPtdioF9q32KvWdDqPZ0+c47dB46N1CDa61mRpOUr6pvFnQysjRYGo32HZ9u2WRjAZhcJAYB1kxNd71vsNQsWC5F9h2e5cddBNu58hBt3HVz0fQzbYoEmqb+KCoJOBtZm7QajhUH2o3ufvGAAazYxPvbqXEQrO7ZsYmJ8rKvXLGj3niYvGT8voDoJtWHq5axIUm96nSweKb/8trX8xd/943mf3FvNETSbPXmad3z6//DS6TOsm5zgl9+2li8dml0yAAAuu2Scu3/12kXLGwv7llMf37FlU8s5gkxGqmS0bnKi5TzJcsK7F85TqETFBMGn9h25IAQC+OD1VzL95tez+8CxlgPRgpOnzwDzodD8exbz4zM/7ajdts1Tyxpw2oXIx/Y+2bL9QslopQ127QKtk7OiujhPoVL1tGpoWLpdNbTv8Cwf2/tky8F7YWXOvsOzfLTN4NmrTlb/1K3dSqTLLhnn1CtnzzsDGh8Ldt/2C0Mf7IYdUN2s3hp2X6Xl6MuqoVGx+8CxRVfzLHwS7JdO69x1Di7tPmG/cubcBWWwM+eST//N0aEPZMs9K6pLp/MUnjlotSlisnixgXjd5ETLFStLaV73OjE+xuTEeMu2k5eML7l6p3n1Ua+Tu9s2T3HfrdcxNTlBMP+p9r5br+PlNqWqF18+s6y/s5p0unrLFU5abYoIgnb/gwfzn5y7XZkyMT7Gh9951QWD7D23XHvB6p/xseDUj88uOcD3Y3DZtnmKx3bexNO7foXHdt7kp9UldLp6yxVOWm2KKA21KpME8OF3XsW2zVNLThQvtAc6Ktk0lnd+9MrZVyeaF7RavTOowWVyYvyC/ixsL12nq7dWygonlaPfc1JFBMG2zVPMfO8FvvD4s5zLZCyCD91wJZ/Zdh3QOihaeXrXr3T0txr/BW3c+UjLds0D/KAGl3tuuZYdf/mN875RPX5RcM8t19b6d0ZVJ/MUK2GFk8oxiDmpIkpD+w7P8qVDs5yrVkidy+RLh2ZfLc801tPbWe6A3GnduZcvlXVj2+Ypdv/6L5xX1tr968NfMTRK2s2/eAzVD4OYkypi+Wi3ywJbfdr7wL+a4qvfmuv61Kybi8K5JFFSs407H2m56jHorEpx3mtKXj7aTf29VZ24+ZvEnV5aeuF3XDoxzmvHL+Lky2cWHeCHvXxS0soziLJxEUHQ7YFsHpBv3HWwq8s1NJ8FnDx9honxMe7/4Dsc6CV1ZRBzUkXMEfRaf+92RY/rzCXVZRBzUkWcEfRyUTfo/ozCdeaS6tTvsnERQQC9HchuT81cZy5plBRRGupVt6dmg1oKKkl1KOaMoFPtlnB2c0bRaylKkgbJIGhQ5zf4XAoqaVRYGmrgah9JJSrmjKCTb+262kdSiYoIgk5LPoNe7eMlJSStBEWUhjot+QxytU/dN6IZBfsOzy55gx5Jg1dEELQr7TR/+h/kVSVLm48oMfikUVFEaahdySeYH6AaB/pBrfYpbT5iseCzHCYNVxFnBDu2bLrgHsMACbV9Au+27NHpfQpWi9KCTxolRQTBts1TLa/nDfUMRMspe5T27ePSgk8aJUUEAdD27mN1DETLqfeXdper0oJPGiVFzBFAf6/pvdyyR0nfPvayG9LKVUwQ9HMg8mqjnSkp+KRR0lMQRMTrgb3ABuAZ4Dcy88UW7bYDn6qefiYzH2zavx94S2a+vZf+LKVfA9Eg7iAkSf3S6xzBTuArmXk18JXq+XmqsLgbuAG4Hrg7Ii5r2H8rcKrHfgxVafV+SatLr6WhrcC7qscPAl8DPtHUZgvwaGa+ABARjwI3A1+IiNcBvwfcAXyxx74MlWUPSaOq1zOCN2Xm96vH/wS8qUWbKeDZhucnqm0AfwD8V+Dlpf5QRNwRETMRMTM3N9dDlyVJjZY8I4iIvwV+rsWuTzY+ycyMiHbL9Vv93ncAP5+ZH4uIDUu1z8w9wB6A6enpjv+OJGlxSwZBZr6n3b6I+EFEXJGZ34+IK4Aftmg2y8/KRwDrmS8h/RtgOiKeqfrxxoj4Wma+C0nSwPRaGtoPbK8ebwf+ukWbA8D7IuKyapL4fcCBzPwfmbkuMzcAvwh82xCQpMHrNQh2Ae+NiO8A76meExHTEfFnANUk8R8AT1Q/9y5MHEuShi8yR6/cPj09nTMzM8PuhiSNlIg4lJnTzduLudaQJKk1g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVrpgb0yzXvsOz3lVL0qpmECxi4ab0CzecWbgpPWAYSFo1LA0tYjk3pZekUWMQLGK5N6WXpFFiECyi3c3nvSm9pNXEIFjEji2bmBgfO2+bN6WXtNo4WbyIhQlhVw1JWs0MgiV4U3pJq52lIUkqnEEgSYUzCCSpcAaBJBXOIJCkwo3kzesjYg74Xo+/5g3AP9fQnVFV+vsHjwF4DKCsY/DmzFzbvHEkg6AOETGTmdPD7sewlP7+wWMAHgPwGIClIUkqnkEgSYUrOQj2DLsDQ1b6+wePAXgMwGNQ7hyBJGleyWcEkiQMAkkq3qoLgoi4OSKORcTxiNjZYv/FEbG32v94RGxo2HdXtf1YRGwZZL/rtNxjEBGXR8RXI+JURDww6H7XqYdj8N6IOBQRR6p/3jTovtelh2NwfUQ8Wf18IyJ+bdB9r0MvY0G1/6rq/4WPD6rPQ5OZq+YHGAO+C7wFeA3wDeCapja/C/zP6vHtwN7q8TVV+4uBjdXvGRv2exrwMfgXwC8CHwEeGPZ7GdIx2Aysqx6/HZgd9vsZwjG4BFhTPb4C+OHC81H56eX9N+x/GPhL4OPDfj/9/lltZwTXA8cz86nM/AnwELC1qc1W4MHq8cPAuyMiqu0PZeYrmfk0cLz6faNm2ccgM3+Umf8X+PHgutsXvRyDw5n5XLX9KDARERcPpNf16uUYvJyZZ6vtrwVGcUVJL2MBEbENeJr5/wZWvdUWBFPAsw3PT1TbWrap/mN/Cbi8w9eOgl6OwWpR1zH4APD1zHylT/3sp56OQUTcEBFHgSPARxqCYVQs+/1HxOuATwCfHkA/V4TVFgRSLSLiWuCzwO8Muy/DkJmPZ+a1wL8G7oqI1w67TwN0D3B/Zp4adkcGZbUFwSxwZcPz9dW2lm0iYg1wKfB8h68dBb0cg9Wip2MQEeuBvwJ+MzO/2/fe9kct/x1k5j8Ap5ifLxklvbz/G4A/iohngI8Cvx8Rd/a7w8O02oLgCeDqiNgYEa9hfgJof1Ob/cD26vFtwMGcnxnaD9xerSTYCFwN/P2A+l2nXo7BarHsYxARk8AjwM7MfGxgPa5fL8dgYzUwEhFvBt4GPDOYbtdm2e8/M38pMzdk5gbgj4E/zMyRXkW3pGHPVtf9A/xb4NvMrxj4ZLXtXuCW6vFrmV8JcJz5gf4tDa/9ZPW6Y8D7h/1ehnQMngFeYP5T4AmaVlqMys9yjwHwKeBHwJMNP28c9vsZ8DH498xPkj4JfB3YNuz3Msj33/Q77qGAVUNeYkKSCrfaSkOSpC4ZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlw/x97kPXxKGrGLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(change_in_loss_array, diff_in_loss_by_if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXgV55CmQF_5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSQfUCFFPyS7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SF9GWBxRIVvR"
   },
   "source": [
    "# Logistic Regression comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UMSQsmBMIYgu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd.functional import hessian\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import scatter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Hlh7lWndIY8Y"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]), download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]), download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cKJ9JRa-I_x8"
   },
   "outputs": [],
   "source": [
    "train_index = []\n",
    "train_labels = []\n",
    "for i, digit in enumerate(train_dataset.targets):\n",
    "    if digit == 1:\n",
    "        train_index.append(i)\n",
    "        train_labels.append(0)\n",
    "    elif digit == 7:\n",
    "        train_index.append(i)\n",
    "        train_labels.append(1)\n",
    "\n",
    "test_index = []\n",
    "test_labels = []\n",
    "for i, digit in enumerate(test_dataset.targets):\n",
    "    if digit == 1:\n",
    "        test_index.append(i)\n",
    "        test_labels.append(0)\n",
    "    elif digit == 7:\n",
    "        test_index.append(i)\n",
    "        test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zE3DWekEIZBu"
   },
   "outputs": [],
   "source": [
    "class One_Seven_Train_Dataset(Dataset):\n",
    "  def __init__(self):\n",
    "      \n",
    "      self.x = train_dataset.data[train_index].float()\n",
    "      self.y = torch.tensor(train_labels)\n",
    "      \n",
    "      #self.n_samples = int(train_dataset.data.shape[0]*alpha)\n",
    "      self.n_samples = len(train_index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      return self.x[index], self.y[index]\n",
    "  def __len__(self):\n",
    "      return self.n_samples\n",
    "\n",
    "class One_Seven_Test_Dataset(Dataset):\n",
    "  def __init__(self):\n",
    "      \n",
    "      self.x = test_dataset.data[test_index].float()#[random_selector].float()\n",
    "      self.y = torch.tensor(test_labels)\n",
    "      \n",
    "      self.n_samples = len(test_index)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      return self.x[index], self.y[index]\n",
    "  def __len__(self):\n",
    "      return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tMStI59nMw8y"
   },
   "outputs": [],
   "source": [
    "class CE_LR(nn.Module):\n",
    "  def __init__(self, input_size,  num_classes):\n",
    "    super(CE_LR, self).__init__()\n",
    "    self.l1 = nn.Linear(input_size, num_classes)\n",
    "    #self.sigmoid = nn.Sigmoid()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.l1(x)\n",
    "    #out = self.sigmoid(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VoalnA0NIY-_"
   },
   "outputs": [],
   "source": [
    "input_size = 784 # 28*28\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "training_size = len(train_index)\n",
    "testing_size = len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lXWEf0v0y_mo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242,  1.1541,  2.7960,  2.8215,  0.3777, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  0.7977,  2.6815,  2.7706,  2.7960,  0.3649, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  1.1923,  2.7706,  2.7706,  2.7960,  0.3649, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          0.4413,  2.5797,  2.7706,  2.2614, -0.0296, -0.3224, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.3395,\n",
       "          2.4778,  2.7706,  2.7706,  0.7722, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.5487,\n",
       "          2.7960,  2.7960,  1.9814, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1696,  2.7960,\n",
       "          2.7706,  2.5669,  0.4159, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.0169,  2.1851,  2.7960,\n",
       "          2.7706,  1.1795, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.8995,  2.7706,  2.7960,\n",
       "          1.9178, -0.2333, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242,  0.5940,  2.6306,  2.7706,  2.0323,\n",
       "         -0.1315, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.0169,  2.7960,  2.7960,  2.7960,  1.5996,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242,  1.4978,  2.7706,  2.7706,  2.7706,  0.0722,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242,  0.1867,  2.3887,  2.7706,  2.7706,  1.7650, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242,  2.5542,  2.7706,  2.7706,  2.0705, -0.2715, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242,  2.7960,  2.7706,  2.7706,  0.7086, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242,  1.5996,  2.8215,  2.7960,  2.7960, -0.0296, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          0.1867,  2.4778,  2.7960,  2.7197,  1.3577, -0.3224, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          0.3904,  2.7706,  2.7960,  2.3760, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          0.3904,  2.7706,  2.7960,  2.3760, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.1187,  2.0323,  2.7960,  2.3760, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "         -0.4242, -0.4242, -0.4242, -0.4242]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_train_dataset = One_Seven_Train_Dataset()\n",
    "((alpha_train_dataset[0][0]/255) - 0.1307)/0.3081"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg-5feqZjxZI"
   },
   "source": [
    "### CE train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aw8_jfivIZG-"
   },
   "outputs": [],
   "source": [
    "alpha_train_dataset = One_Seven_Train_Dataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=alpha_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = CE_LR(input_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device) # can change -1 to 100\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "alpha_test_dataset = One_Seven_Test_Dataset()\n",
    "test_loader = torch.utils.data.DataLoader(dataset=alpha_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        # 把一个batch reshape 成一个 100 by 784 的 vector 来做prediction\n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        # value, index\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    acc = 100 * n_correct/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCXPmvwykK_u",
    "outputId": "631be107-7f6c-4048-ae61-36fafef42406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.52057327785484"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxDfwjcklxlu",
    "outputId": "9a6c3569-a8c9-461b-e8f9-98bba6801dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 784])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUpj3Ax4mdms"
   },
   "outputs": [],
   "source": [
    "w = torch.cat(tuple([_.view(-1) for _ in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDR_5pa0kctY"
   },
   "outputs": [],
   "source": [
    "def CE_loss_new_all2(w):\n",
    "\n",
    "    divide1 = 2*784\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=alpha_train_dataset, batch_size=training_size, shuffle=False)\n",
    "    examples = iter(train_loader)\n",
    "    images, labels = examples.next()\n",
    "\n",
    "    out1 = F.linear(images.reshape(-1, 784).to(device), w[:divide1].reshape(2,784), w[divide1:])\n",
    "\n",
    "    loss = criterion(out1, labels.to(device))*training_size\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Khxw2pmMoQnf"
   },
   "outputs": [],
   "source": [
    "def CE_loss_single_point(w, i):\n",
    "\n",
    "    divide1 = 2*784\n",
    "    \n",
    "    images = alpha_train_dataset[i][0].float()\n",
    "\n",
    "    labels = torch.tensor([train_labels[i]])\n",
    "\n",
    "    out1 = F.linear(images.reshape(-1, 784).to(device), w[:divide1].reshape(2,784), w[divide1:])\n",
    "\n",
    "    loss = criterion(out1, labels.to(device))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def CE_loss_256(w):\n",
    "\n",
    "    divide1 = 2*784\n",
    "    \n",
    "    images = alpha_train_dataset[256][0].float()\n",
    "\n",
    "    labels = torch.tensor([train_labels[256]])\n",
    "\n",
    "    #out1 = F.linear(images.reshape(-1, 784).to(device), w[:divide1].reshape(2,784), w[divide1:])\n",
    "\n",
    "\n",
    "    mat1 = images.reshape(-1,784).to(device)\n",
    "\n",
    "    mat2 = w[:divide1].reshape(2,784).t()\n",
    "    \n",
    "    out1 = w[divide1:].reshape(1,2) + torch.matmul(mat1, mat2) \n",
    "    loss = criterion(out1, labels.to(device))\n",
    "\n",
    "    #loss = out1\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHOf5uEwpEYg",
    "outputId": "91a4406d-34dc-40c2-d35f-f57676d2de33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6398, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "\n",
    "\n",
    "for i in range(len(train_index)):\n",
    "    out1 = model(alpha_train_dataset[i][0].reshape(-1,784).float().to(device))\n",
    "    loss1 = criterion(out1, torch.tensor([alpha_train_dataset[i][1]]).to(device))\n",
    "    if loss1 > 2.6:\n",
    "        print(loss1)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrT0auYnCmrh",
    "outputId": "ec7d5706-fa22-4219-8102-212af23fe386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMpCHA1H12Ox",
    "outputId": "a0f97dfe-0ec4-428a-f030-07d6cdb92fec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6398, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CE_loss_single_point(w.clone().detach().requires_grad_(True), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEKZW_BF4w5h",
    "outputId": "ef51887a-a65f-4df3-8afa-090f6d851006"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6398, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CE_loss_256(w.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pq39KmKa2sbe"
   },
   "outputs": [],
   "source": [
    "Hessian = hessian(CE_loss_256, w.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dI8FwypB3OQ-",
    "outputId": "c578a183-d4c1-4737-e6f7-69fcf44fa14a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0096, -0.0096],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0096,  0.0096]])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0l_QTALGqNfM",
    "outputId": "787c84c6-5f77-4952-fa8d-e7d59dec2cff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1349.2200, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raRRDw7noIKK",
    "outputId": "9a96640d-f8c3-4423-cc1b-9c72604d0c1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2364.5969, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CE_loss_new_all2(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sOy8JtVnaGM"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "   Hessian = hessian(CE_loss_new_all2, w.clone().detach().requires_grad_(True))#/training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YaS_cZM-4AxB",
    "outputId": "7199d598-c55f-4991-ac3a-6c26468f4af3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.3758, -1.3758],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -1.3758,  1.3758]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wVmMjFycnpnV",
    "outputId": "525b9afc-a984-45c0-df33-c4bd808e36c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1570)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Hessian[3] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wk07rRU4nq2T",
    "outputId": "221cf9e8-5bed-4d78-8cf8-c9d3e4f10352"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0089,  0.0109,  0.0035,  ..., -0.0137, -0.0169, -0.0038],\n",
       "         [-0.0154,  0.0336, -0.0277,  ...,  0.0301, -0.0080,  0.0077]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0335, -0.0064], requires_grad=True)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "5pW_rNggwoAa",
    "outputId": "b51ff45a-ee6c-4873-df49-2f96eab0a891"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1f96068c10>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset.data[1081], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igM4hwG8026L",
    "outputId": "b9a61b9f-65f2-482a-c9c2-a3654aae11ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index[256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12KniTAZB_S1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usHiw50LeH9z"
   },
   "source": [
    "### BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SVw6F5vYeJP9"
   },
   "outputs": [],
   "source": [
    "class BCE_LR(nn.Module):\n",
    "  def __init__(self, input_size,  num_classes):\n",
    "    super(BCE_LR, self).__init__()\n",
    "    self.linear = nn.Linear(input_size, num_classes-1, bias = False)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    out = self.linear(x)\n",
    "    out = self.sigmoid(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-ueJMVt6ejyW"
   },
   "outputs": [],
   "source": [
    "input_size = 784 # 28*28\n",
    "num_classes = 2\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "training_size = len(train_index)\n",
    "testing_size = len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2163"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nNHXItgiej1c"
   },
   "outputs": [],
   "source": [
    "alpha_train_dataset = One_Seven_Train_Dataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=alpha_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = BCE_LR(input_size, num_classes).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        #images = images.reshape(-1, 28*28).to(device) # can change -1 to 100\n",
    "        images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "\n",
    "        labels = labels.reshape(-1, 1).float().to(device)\n",
    "\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "alpha_test_dataset = One_Seven_Test_Dataset()\n",
    "test_loader = torch.utils.data.DataLoader(dataset=alpha_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        # 把一个batch reshape 成一个 100 by 784 的 vector 来做prediction\n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        # value, index\n",
    "        \n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (output.reshape(-1).round().eq(labels)*1).sum().item()\n",
    "    \n",
    "    acc = 100 * n_correct/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def save_checkpoint_classification(file_path, silent=True):\n",
    "        model_states = {'classification': model.state_dict(), }\n",
    "        optim_states = {'classification': optimizer.state_dict(), }\n",
    "        states = {'epoch': 10,\n",
    "                  'model_states': model_states,\n",
    "                  'optim_states': optim_states}\n",
    "        with open(file_path, mode='wb+') as f:\n",
    "            torch.save(states, f)\n",
    "        if not silent:\n",
    "            print(\n",
    "                \"=> saved checkpoint '{}' (iter {})\".format(\n",
    "                    file_path, self.global_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint_classification(\"../checkpoints/fenchel/mnist/MNIST_LogisticRegression/classOneAndSevenAll.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCE_LR(\n",
       "  (linear): Linear(in_features=784, out_features=1, bias=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLSgdI_3j-8L",
    "outputId": "6228f4c5-38f3-4c22-826e-e70e17e050a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.19694868238558"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "h_dCioBpidq9"
   },
   "outputs": [],
   "source": [
    "w = list(model.parameters())[0][0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YW8CB5VlNyx",
    "outputId": "4dc37277-9892-4e9c-a48d-edb1a96f628e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100., grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "\n",
    "\n",
    "for i in range(len(train_index)):\n",
    "    out1 = model(alpha_train_dataset[i][0].reshape(-1,784).float().to(device))\n",
    "    loss1 = criterion(out1[0], torch.tensor([alpha_train_dataset[i][1]]).float().to(device))\n",
    "    #total_loss += loss1\n",
    "    if loss1 > 2.6:\n",
    "        print(loss1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "DPMwI4oflN1l"
   },
   "outputs": [],
   "source": [
    "def BCE_loss_all(w):\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=alpha_train_dataset, batch_size=training_size, shuffle=False)\n",
    "    examples = iter(train_loader)\n",
    "    images, labels = examples.next()\n",
    "\n",
    "    images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "\n",
    "    out1 = torch.sigmoid(F.linear(images, w.reshape(1,784)))\n",
    "\n",
    "\n",
    "    #out1 = torch.sigmoid(F.linear(images.reshape(-1, 784).to(device), w.reshape(1,784)))\n",
    "\n",
    "    loss = criterion(out1.reshape(-1), labels.float().to(device))*training_size\n",
    "    print(loss)\n",
    "    return loss\n",
    "\n",
    "def BCE_loss_single_point(w, i):\n",
    "    \n",
    "    images = alpha_train_dataset[i][0].float()\n",
    "\n",
    "    temp_label = torch.tensor([train_labels[i]]).float()\n",
    "\n",
    "    out1 = torch.sigmoid(F.linear(images.reshape(-1, 784).to(device), w.reshape(1,784)))\n",
    "\n",
    "    loss = criterion(out1[0], temp_label.to(device))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def BCE_loss_grad_train_point(w, i):\n",
    "    \n",
    "    w = w.clone().detach().requires_grad_(True)\n",
    "\n",
    "    images = alpha_train_dataset[i][0].float()\n",
    "\n",
    "    images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "\n",
    "    temp_label = torch.tensor([train_labels[i]]).float()\n",
    "\n",
    "    out1 = torch.sigmoid(F.linear(images, w.reshape(1,784)))\n",
    "\n",
    "    loss = criterion(out1[0], temp_label.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    return w.grad\n",
    "\n",
    "\n",
    "def BCE_loss_grad_test_point(w, i):\n",
    "    \n",
    "    w = w.clone().detach().requires_grad_(True)\n",
    "\n",
    "    images = alpha_test_dataset[i][0].float()\n",
    "\n",
    "    images = ((images.reshape(-1, 28*28)/255- 0.1307)/0.3081).to(device)\n",
    "\n",
    "    temp_label = torch.tensor([test_labels[i]]).float()\n",
    "\n",
    "    out1 = torch.sigmoid(F.linear(images, w.reshape(1,784)))\n",
    "\n",
    "    loss = criterion(out1[0], temp_label.to(device))\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    return w.grad\n",
    "\n",
    "\n",
    "\n",
    "def BCE_loss_34(w):\n",
    "    \n",
    "    images = alpha_train_dataset[34][0].float()\n",
    "\n",
    "    temp_label = torch.tensor([train_labels[34]]).float()\n",
    "\n",
    "    out1 = torch.sigmoid(F.linear(images.reshape(-1, 784).to(device), w.reshape(1,784)))\n",
    "\n",
    "    loss = criterion(out1[0], temp_label.to(device))\n",
    "\n",
    "    ####\n",
    "\n",
    "    #out1 = F.linear(images.reshape(-1, 784).to(device), w.reshape(1,784))\n",
    "\n",
    "    #images = alpha_train_dataset[34][0].float().reshape(-1, 784)[0].t()\n",
    "\n",
    "    #out1 = torch.matmul(images, w)\n",
    "\n",
    "    #out1 = torch.sigmoid(out1)\n",
    "    \n",
    "    #loss = criterion(out1, temp_label.to(device))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "-m7JLcmWojM9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(705.5736, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "   Hessian = hessian(BCE_loss_all, w.clone().detach().requires_grad_(True))/training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../checkpoints/fenchel/mnist/MNIST_LogisticRegression/numpy_hessian_first1000.pt.npy\", Hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCrCI7vPotM3",
    "outputId": "96dc6921-133b-4058-9f87-b50494764103"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9469e-03,  4.9516e-03,  4.9382e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9340e-03,  4.9309e-03,  4.9105e-03,  4.8743e-03,\n",
       "         5.0337e-03,  5.1353e-03,  5.2680e-03,  5.1394e-03,  4.9680e-03,\n",
       "         4.9245e-03,  4.9332e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9361e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9367e-03,  4.9478e-03,  4.9182e-03,  4.9139e-03,\n",
       "         4.9115e-03,  4.8437e-03,  4.7570e-03,  5.1103e-03,  6.2357e-03,\n",
       "         6.6578e-03,  5.6990e-03,  5.1219e-03,  4.8897e-03,  4.8921e-03,\n",
       "         4.8972e-03,  4.9099e-03,  4.9312e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9365e-03,\n",
       "         4.9357e-03,  4.9323e-03,  4.9347e-03,  4.9164e-03,  4.9027e-03,\n",
       "         4.9386e-03,  4.8337e-03,  4.4693e-03,  4.0528e-03,  3.4849e-03,\n",
       "         3.3904e-03,  3.7111e-03,  4.5272e-03,  4.7185e-03,  3.9733e-03,\n",
       "         3.2949e-03,  3.2916e-03,  3.5769e-03,  3.9286e-03,  4.2993e-03,\n",
       "         4.6629e-03,  4.8826e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9331e-03,  4.9257e-03,  4.9201e-03,\n",
       "         4.9237e-03,  4.8848e-03,  4.7739e-03,  4.7294e-03,  4.3624e-03,\n",
       "         3.7221e-03,  2.7427e-03,  1.6818e-03,  7.7653e-04,  5.3941e-04,\n",
       "         4.6057e-04,  3.2024e-04,  3.4312e-05,  2.8564e-05,  8.2511e-04,\n",
       "         1.7001e-03,  2.6516e-03,  3.5136e-03,  4.2807e-03,  4.7443e-03,\n",
       "         4.9314e-03,  4.9355e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9279e-03,  4.8885e-03,  4.8600e-03,  4.7962e-03,  4.6119e-03,\n",
       "         4.1978e-03,  3.6507e-03,  2.8895e-03,  1.4640e-03, -2.1746e-04,\n",
       "        -2.2140e-03, -4.1219e-03, -5.4735e-03, -6.0361e-03, -5.9660e-03,\n",
       "        -5.2307e-03, -4.0284e-03, -2.0817e-03, -1.4312e-04,  1.6985e-03,\n",
       "         3.1939e-03,  4.2266e-03,  4.7554e-03,  4.9355e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9322e-03,  4.9093e-03,  4.8422e-03,\n",
       "         4.7075e-03,  4.4016e-03,  3.8697e-03,  3.0687e-03,  2.0745e-03,\n",
       "         7.2346e-04, -1.4761e-03, -4.1530e-03, -6.9060e-03, -9.3242e-03,\n",
       "        -1.0978e-02, -1.2119e-02, -1.2059e-02, -1.0776e-02, -8.3309e-03,\n",
       "        -5.0046e-03, -1.5716e-03,  1.1097e-03,  3.0518e-03,  4.1366e-03,\n",
       "         4.7475e-03,  4.9289e-03,  4.9356e-03,  4.9359e-03,  4.9358e-03,\n",
       "         4.9232e-03,  4.8316e-03,  4.6771e-03,  4.4257e-03,  3.9611e-03,\n",
       "         3.2083e-03,  2.1319e-03,  9.5866e-04, -5.5587e-04, -2.7672e-03,\n",
       "        -5.2693e-03, -8.0379e-03, -1.0556e-02, -1.3161e-02, -1.4859e-02,\n",
       "        -1.5168e-02, -1.3605e-02, -1.0215e-02, -5.7936e-03, -1.6203e-03,\n",
       "         1.2953e-03,  3.1547e-03,  4.1634e-03,  4.7194e-03,  4.9184e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9306e-03,  4.9055e-03,  4.7846e-03,\n",
       "         4.5755e-03,  4.2547e-03,  3.8159e-03,  3.1901e-03,  2.3214e-03,\n",
       "         1.1149e-03, -1.2481e-04, -1.6527e-03, -3.7910e-03, -6.4557e-03,\n",
       "        -9.0811e-03, -1.2401e-02, -1.5630e-02, -1.6942e-02, -1.4759e-02,\n",
       "        -1.0202e-02, -5.1999e-03, -9.3260e-04,  1.8775e-03,  3.3644e-03,\n",
       "         4.2906e-03,  4.7425e-03,  4.8902e-03,  4.9270e-03,  4.9248e-03,\n",
       "         4.9296e-03,  4.9021e-03,  4.7719e-03,  4.5367e-03,  4.1484e-03,\n",
       "         3.6983e-03,  3.1702e-03,  2.4602e-03,  1.6663e-03,  5.8655e-04,\n",
       "        -6.2286e-04, -2.1890e-03, -4.4517e-03, -7.4043e-03, -1.2175e-02,\n",
       "        -1.6988e-02, -1.8398e-02, -1.4738e-02, -8.7808e-03, -3.6912e-03,\n",
       "         1.1895e-04,  2.2221e-03,  3.4883e-03,  4.4421e-03,  4.8229e-03,\n",
       "         4.8911e-03,  4.9271e-03,  4.9326e-03,  4.9338e-03,  4.8843e-03,\n",
       "         4.7481e-03,  4.4759e-03,  4.0081e-03,  3.6316e-03,  3.1852e-03,\n",
       "         2.5537e-03,  1.8722e-03,  1.0270e-03, -1.0097e-05, -1.0641e-03,\n",
       "        -2.7527e-03, -6.3208e-03, -1.3387e-02, -1.9283e-02, -1.9049e-02,\n",
       "        -1.3128e-02, -6.3247e-03, -1.4891e-03,  1.2508e-03,  2.6663e-03,\n",
       "         3.6597e-03,  4.4421e-03,  4.8833e-03,  4.9266e-03,  4.9344e-03,\n",
       "         4.9349e-03,  4.9357e-03,  4.8970e-03,  4.7687e-03,  4.4726e-03,\n",
       "         3.9660e-03,  3.6821e-03,  3.4603e-03,  2.9676e-03,  2.4108e-03,\n",
       "         1.8131e-03,  1.1845e-03,  6.0535e-04, -8.9191e-04, -6.0841e-03,\n",
       "        -1.5749e-02, -2.1405e-02, -1.8595e-02, -1.0224e-02, -3.1922e-03,\n",
       "         4.6283e-04,  2.0873e-03,  3.2184e-03,  3.9536e-03,  4.4939e-03,\n",
       "         4.8684e-03,  4.9078e-03,  4.9309e-03,  4.9333e-03,  4.9355e-03,\n",
       "         4.9192e-03,  4.8392e-03,  4.5944e-03,  4.1229e-03,  3.8772e-03,\n",
       "         3.7457e-03,  3.4659e-03,  3.0982e-03,  2.6487e-03,  2.1792e-03,\n",
       "         1.8579e-03, -1.8979e-04, -7.8312e-03, -1.8812e-02, -2.2930e-02,\n",
       "        -1.7097e-02, -6.7738e-03, -7.7269e-04,  1.3349e-03,  2.4863e-03,\n",
       "         3.4409e-03,  4.0949e-03,  4.4734e-03,  4.7515e-03,  4.8806e-03,\n",
       "         4.9325e-03,  4.9359e-03,  4.9359e-03,  4.9296e-03,  4.9042e-03,\n",
       "         4.7333e-03,  4.4364e-03,  4.0922e-03,  3.9890e-03,  3.9364e-03,\n",
       "         3.7097e-03,  3.2982e-03,  2.8173e-03,  2.0582e-03, -1.3545e-03,\n",
       "        -1.1499e-02, -2.2006e-02, -2.3816e-02, -1.4654e-02, -4.0415e-03,\n",
       "        -2.1887e-04,  1.2328e-03,  2.3595e-03,  3.2885e-03,  3.9441e-03,\n",
       "         4.4106e-03,  4.7621e-03,  4.8843e-03,  4.9352e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9197e-03,  4.8396e-03,  4.7023e-03,\n",
       "         4.4276e-03,  4.1439e-03,  4.0818e-03,  3.8157e-03,  3.1956e-03,\n",
       "         2.3124e-03,  4.1083e-04, -4.7300e-03, -1.5629e-02, -2.4624e-02,\n",
       "        -2.2999e-02, -1.1320e-02, -2.6255e-03,  7.6933e-05,  1.2893e-03,\n",
       "         2.3739e-03,  3.2347e-03,  3.8980e-03,  4.4843e-03,  4.8046e-03,\n",
       "         4.9224e-03,  4.9356e-03,  4.9359e-03,  4.9357e-03,  4.9356e-03,\n",
       "         4.9269e-03,  4.8775e-03,  4.7887e-03,  4.6182e-03,  4.3140e-03,\n",
       "         4.0714e-03,  3.6553e-03,  2.7519e-03,  1.1231e-03, -1.8878e-03,\n",
       "        -8.5231e-03, -1.8745e-02, -2.5017e-02, -1.9756e-02, -7.9238e-03,\n",
       "        -1.2689e-03,  7.8194e-04,  1.8526e-03,  2.9211e-03,  3.7663e-03,\n",
       "         4.2862e-03,  4.7074e-03,  4.8779e-03,  4.9320e-03,  4.9358e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9355e-03,  4.9350e-03,  4.9128e-03,\n",
       "         4.8263e-03,  4.7366e-03,  4.5557e-03,  4.2926e-03,  3.6546e-03,\n",
       "         2.3931e-03,  1.2700e-04, -3.9816e-03, -1.1166e-02, -1.9818e-02,\n",
       "        -2.2857e-02, -1.5065e-02, -5.0984e-03, -3.2404e-05,  1.5907e-03,\n",
       "         2.7512e-03,  3.6437e-03,  4.2317e-03,  4.7037e-03,  4.8626e-03,\n",
       "         4.8390e-03,  4.8906e-03,  4.9253e-03,  4.9358e-03,  4.9324e-03,\n",
       "         4.9358e-03,  4.9291e-03,  4.9249e-03,  4.8557e-03,  4.8232e-03,\n",
       "         4.7612e-03,  4.4329e-03,  3.6157e-03,  1.8759e-03, -9.0881e-04,\n",
       "        -5.7090e-03, -1.2342e-02, -1.8732e-02, -1.8809e-02, -1.1003e-02,\n",
       "        -3.0150e-03,  1.0084e-03,  2.3723e-03,  3.5113e-03,  4.3753e-03,\n",
       "         4.7042e-03,  4.8202e-03,  4.9469e-03,  4.8413e-03,  4.8949e-03,\n",
       "         4.9286e-03,  4.9319e-03,  4.9358e-03,  4.9332e-03,  4.9255e-03,\n",
       "         4.9309e-03,  4.8840e-03,  4.8413e-03,  4.7405e-03,  4.3197e-03,\n",
       "         3.1617e-03,  1.2891e-03, -2.0991e-03, -6.7004e-03, -1.2123e-02,\n",
       "        -1.5925e-02, -1.4343e-02, -7.9232e-03, -1.8827e-03,  1.7486e-03,\n",
       "         3.2325e-03,  4.3349e-03,  4.8321e-03,  5.1136e-03,  5.1344e-03,\n",
       "         4.9726e-03,  4.8409e-03,  4.8974e-03,  4.9358e-03,  4.9336e-03,\n",
       "         4.9359e-03,  4.9358e-03,  4.9356e-03,  4.9342e-03,  4.8988e-03,\n",
       "         4.7446e-03,  4.5110e-03,  3.8914e-03,  2.4837e-03,  1.0241e-04,\n",
       "        -3.3123e-03, -7.2168e-03, -1.1078e-02, -1.2797e-02, -1.0970e-02,\n",
       "        -6.1935e-03, -1.4962e-03,  1.7494e-03,  3.3394e-03,  4.5404e-03,\n",
       "         4.9932e-03,  5.1509e-03,  5.1525e-03,  5.1334e-03,  4.9210e-03,\n",
       "         4.9176e-03,  4.9358e-03,  4.9356e-03,  4.9355e-03,  4.9358e-03,\n",
       "         4.9344e-03,  4.9203e-03,  4.9390e-03,  4.6830e-03,  4.1182e-03,\n",
       "         3.2584e-03,  1.5217e-03, -1.1247e-03, -4.0923e-03, -7.5494e-03,\n",
       "        -9.6864e-03, -1.0352e-02, -8.8879e-03, -5.3274e-03, -1.7244e-03,\n",
       "         1.3101e-03,  2.9810e-03,  4.1799e-03,  4.7592e-03,  5.0231e-03,\n",
       "         4.9826e-03,  5.0617e-03,  5.0024e-03,  4.9274e-03,  4.9340e-03,\n",
       "         4.9359e-03,  4.9355e-03,  4.9358e-03,  4.9344e-03,  4.9233e-03,\n",
       "         4.7978e-03,  4.2067e-03,  3.2024e-03,  1.9044e-03, -3.6651e-05,\n",
       "        -2.5549e-03, -5.3647e-03, -7.6546e-03, -8.8828e-03, -9.1353e-03,\n",
       "        -8.1078e-03, -5.3604e-03, -2.0976e-03,  7.7637e-04,  2.7351e-03,\n",
       "         4.0300e-03,  4.6335e-03,  4.8321e-03,  4.8572e-03,  4.9269e-03,\n",
       "         4.9383e-03,  4.9311e-03,  4.9353e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9332e-03,  4.6533e-03,  3.9123e-03,\n",
       "         2.7430e-03,  1.2002e-03, -5.4609e-04, -2.7912e-03, -4.9759e-03,\n",
       "        -6.2585e-03, -6.9299e-03, -7.1636e-03, -6.3190e-03, -4.0538e-03,\n",
       "        -1.1984e-03,  1.3751e-03,  3.2515e-03,  4.1130e-03,  4.5282e-03,\n",
       "         4.7368e-03,  4.8366e-03,  4.9279e-03,  4.9285e-03,  4.9321e-03,\n",
       "         4.9346e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9277e-03,\n",
       "         4.9097e-03,  4.6850e-03,  4.1908e-03,  3.4059e-03,  2.3500e-03,\n",
       "         1.3199e-03, -7.2623e-05, -1.3315e-03, -1.7740e-03, -2.1024e-03,\n",
       "        -2.4849e-03, -1.9755e-03, -4.0998e-04,  1.5778e-03,  3.1845e-03,\n",
       "         4.1197e-03,  4.5630e-03,  4.7759e-03,  4.8358e-03,  4.8804e-03,\n",
       "         4.9311e-03,  4.9356e-03,  4.9348e-03,  4.9357e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9141e-03,  4.7683e-03,\n",
       "         4.5521e-03,  4.1668e-03,  3.5497e-03,  2.9158e-03,  2.3899e-03,\n",
       "         2.0644e-03,  1.9149e-03,  1.7755e-03,  1.3209e-03,  1.5734e-03,\n",
       "         2.2177e-03,  3.2932e-03,  4.0083e-03,  4.4279e-03,  4.7185e-03,\n",
       "         4.8548e-03,  4.8794e-03,  4.8874e-03,  4.9337e-03,  4.9353e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9159e-03,  4.8306e-03,  4.6903e-03,\n",
       "         4.5454e-03,  4.4135e-03,  4.3290e-03,  4.2805e-03,  4.1242e-03,\n",
       "         3.9845e-03,  3.6914e-03,  3.7314e-03,  3.9362e-03,  4.2754e-03,\n",
       "         4.4494e-03,  4.6386e-03,  4.8083e-03,  4.8905e-03,  4.8989e-03,\n",
       "         4.9049e-03,  4.9303e-03,  4.9359e-03,  4.9356e-03,  4.9359e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03,\n",
       "         4.9348e-03,  4.9301e-03,  4.9208e-03,  4.9015e-03,  4.9004e-03,\n",
       "         4.9099e-03,  4.8721e-03,  4.8780e-03,  4.8550e-03,  4.7974e-03,\n",
       "         4.7810e-03,  4.7995e-03,  4.7940e-03,  4.8036e-03,  4.8479e-03,\n",
       "         4.8993e-03,  4.9207e-03,  4.9221e-03,  4.9169e-03,  4.9325e-03,\n",
       "         4.9359e-03,  4.9359e-03,  4.9359e-03,  4.9359e-03])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hessian[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "KQppzE2f3sLq"
   },
   "outputs": [],
   "source": [
    "damping_matrix = torch.tensor(np.diag(np.full(Hessian.shape[0],0.001),0)).to(device)\n",
    "damping_hessian = Hessian + damping_matrix\n",
    "inv_hessian = torch.linalg.inv(damping_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_C-d6Gd37Fh",
    "outputId": "bfc76c4d-ec71-4abe-97b2-dff98ffee0e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[996.7611,  -3.2389,  -3.2389,  ...,  -3.2389,  -3.2389,  -3.2389],\n",
       "        [ -3.2389, 996.7611,  -3.2389,  ...,  -3.2389,  -3.2389,  -3.2389],\n",
       "        [ -3.2389,  -3.2389, 996.7611,  ...,  -3.2389,  -3.2389,  -3.2389],\n",
       "        ...,\n",
       "        [ -3.2389,  -3.2389,  -3.2389,  ..., 996.7611,  -3.2389,  -3.2389],\n",
       "        [ -3.2389,  -3.2389,  -3.2389,  ...,  -3.2389, 996.7611,  -3.2389],\n",
       "        [ -3.2389,  -3.2389,  -3.2389,  ...,  -3.2389,  -3.2389, 996.7611]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../checkpoints/fenchel/mnist/MNIST_LogisticRegression/numpy_inv_hessian_classOneAndSevenAll.pt\", Hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "D-M69OwQ3lWy"
   },
   "outputs": [],
   "source": [
    "def calculate_if(train_index, test_index, inv_Hessian):\n",
    "    # test point should be alpha_test_dataset[10]\n",
    "\n",
    "    test_loss = BCE_loss_grad_test_point(w, test_index)\n",
    "   \n",
    "    train_loss = BCE_loss_grad_train_point(w, train_index)\n",
    "#     print(test_loss)\n",
    "    print(train_loss)\n",
    "    if_score = -torch.matmul(torch.matmul(test_loss.t().double(), inv_Hessian), train_loss.double())\n",
    "\n",
    "    return if_score\n",
    "\n",
    "def calculate_if_no_hessian(train_index, test_index):\n",
    "    # test point should be alpha_test_dataset[10]\n",
    "\n",
    "    test_loss = BCE_loss_grad_test_point(w, test_index)\n",
    "\n",
    "    train_loss = BCE_loss_grad_train_point(w, train_index)\n",
    "\n",
    "    if_score = -torch.matmul(test_loss.t().double(), train_loss.double())\n",
    "\n",
    "    return if_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,  0.0214,  0.0518,\n",
      "         0.0523,  0.0070, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079,  0.0148,  0.0497,  0.0514,  0.0518,  0.0068, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,  0.0221,  0.0514,  0.0514,\n",
      "         0.0518,  0.0068, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "         0.0082,  0.0478,  0.0514,  0.0419, -0.0005, -0.0060, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079,  0.0063,  0.0459,  0.0514,  0.0514,  0.0143,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,  0.0287,\n",
      "         0.0518,  0.0518,  0.0367, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0031,  0.0518,  0.0514,  0.0476,  0.0077, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0003,  0.0405,  0.0518,\n",
      "         0.0514,  0.0219, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079,  0.0167,  0.0514,  0.0518,  0.0356, -0.0043, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079,  0.0110,  0.0488,  0.0514,  0.0377,\n",
      "        -0.0024, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0003,\n",
      "         0.0518,  0.0518,  0.0518,  0.0297, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079,  0.0278,  0.0514,  0.0514,  0.0514,  0.0013,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,  0.0035,  0.0443,\n",
      "         0.0514,  0.0514,  0.0327, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079,  0.0473,  0.0514,  0.0514,  0.0384, -0.0050, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,  0.0518,  0.0514,\n",
      "         0.0514,  0.0131, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079,  0.0297,  0.0523,  0.0518,  0.0518, -0.0005, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079,  0.0035,  0.0459,  0.0518,  0.0504,\n",
      "         0.0252, -0.0060, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "         0.0072,  0.0514,  0.0518,  0.0440, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079,  0.0072,  0.0514,  0.0518,  0.0440,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0022,  0.0377,  0.0518,  0.0440, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079,\n",
      "        -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079, -0.0079])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0500, dtype=torch.float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_if(0,1,inv_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calculate_if() missing 1 required positional argument: 'inv_Hessian'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcalculate_if\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: calculate_if() missing 1 required positional argument: 'inv_Hessian'"
     ]
    }
   ],
   "source": [
    "calculate_if_no_hessian(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "N118rNVg3EGz",
    "outputId": "bef602f9-5c58-49ea-c1ee-5042b33cafaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d4844e280>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMrUlEQVR4nO3dX6gc9RnG8eepbUDSKLFBPdpDE4sRpVAjIRRaSkvTar2JRVsMWCJITy+0JOBFJQXrhRcitcGrwimapiW1FFMxSmkbQsFWoXqUNCcmJtqQ5t8hsURSe2Ma8/biTMox2Z092ZnZ2ZP3+4HD7s67s/Oy+mRm9zezP0eEAFz8PtZ2AwAGg7ADSRB2IAnCDiRB2IEkPj7Ijdnmq3+gYRHhTssr7dlt32Z7r+13bD9U5bUANMv9jrPbvkTSPklfl3RY0muSVkfE7pJ12LMDDWtiz75C0jsRsT8iTkn6jaRVFV4PQIOqhP1aSYdmPD5cLPsI22O2J2xPVNgWgIqqfEHX6VDhvMP0iBiXNC5xGA+0qcqe/bCk0RmPPy3paLV2ADSlSthfk3S97SW250m6W9LWetoCULe+D+Mj4rTtByT9UdIlkp6OiDdr6wxArfoeeutrY3xmBxrXyEk1AOYOwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASfc/PLkm2D0h6X9KHkk5HxPI6mgJQv0phL3w1Iv5Vw+sAaBCH8UASVcMekv5k+3XbY52eYHvM9oTtiYrbAlCBI6L/le1rIuKo7SslbZP0g4h4qeT5/W8MwKxEhDstr7Rnj4ijxe1xSc9JWlHl9QA0p++w255ve8HZ+5K+IWlXXY0BqFeVb+OvkvSc7bOv8+uI+EMtXeEjFi9eXFpfunRp19o999xTuu6SJUtK6/v37y+tX3fddaX1zZs3d61t3LixdN0PPvigtI4L03fYI2K/pM/X2AuABjH0BiRB2IEkCDuQBGEHkiDsQBKVzqC74I1xBl1H11xzTWn9lVdeKa2Pjo52rRVDo101/d+/bPsPP/xw6bqPPvpo3e2k0MgZdADmDsIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9iFw6aWXltbXr1/fd/3UqVOl646Pj5fWDx48WFp//PHHS+tl4+xHjhwpXfeWW24prb/77rul9awYZweSI+xAEoQdSIKwA0kQdiAJwg4kQdiBJBhnnwMuv/zy0vqTTz7Ztfbiiy+Wrvvss8+W1q+++urSeq+x8rJx9hMnTpSuu2zZstL6oUOHSutZMc4OJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0lUmbIZA3Ly5MnS+r333tvYtnuNs/f6Xfqm1sWF67lnt/207eO2d81YdoXtbbbfLm4XNtsmgKpmcxj/C0m3nbPsIUnbI+J6SduLxwCGWM+wR8RLks49r3GVpE3F/U2S7qi3LQB16/cz+1URMSVJETFl+8puT7Q9Jmmsz+0AqEnjX9BFxLikcYkLYYA29Tv0dsz2iCQVt8frawlAE/oN+1ZJa4r7ayQ9X087AJrS8zDe9jOSviJpke3Dkn4s6TFJv7V9n6SDkr7dZJNoz8qVK0vrvX4PoWwsfd68eaXr9vo9fVyYnmGPiNVdSl+ruRcADeJ0WSAJwg4kQdiBJAg7kARhB5LgEleUuvHGGxt77cnJydL6vn37Gtt2RuzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmT63UJ65133tnYtrds2dLYa+N87NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ZO79dZbS+uXXXZZY9t++eWXG3ttnI89O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTj7RW7BggWl9RUrVpTWe03J3MuGDRu61l599dVKr40L03PPbvtp28dt75qx7BHbR2zvKP5ub7ZNAFXN5jD+F5Ju67B8Q0TcXPz9vt62ANStZ9gj4iVJJwbQC4AGVfmC7gHbO4vD/IXdnmR7zPaE7YkK2wJQUb9h/5mkz0q6WdKUpCe6PTEixiNieUQs73NbAGrQV9gj4lhEfBgRZyT9XFL5V7oAWtdX2G2PzHj4LUm7uj0XwHBwr3FU289I+oqkRZKOSfpx8fhmSSHpgKTvR8RUz43Z1QZtccHWrVtXWn/iia6fwGqxaNGirrX33nuv0W1nFRHutLznSTURsbrD4qcqdwRgoDhdFkiCsANJEHYgCcIOJEHYgSS4xPUi1+SUy5I0Pj5eWmd4bXiwZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJHpe4lrrxrjEdeDOnDlTaf2TJ0+W1m+66abS+tRUzyufUbNul7iyZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJLie/SKwcuXKvtftdZ7FCy+8UFpnHH3uYM8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwPfscMH/+/NL6xMRE19oNN9xQum6v//7Lli0rre/cubO0jsHr+3p226O2/2x7j+03ba8tll9he5vtt4vbhXU3DaA+szmMPy3pwYi4UdIXJN1v+yZJD0naHhHXS9pePAYwpHqGPSKmIuKN4v77kvZIulbSKkmbiqdtknRHQz0CqMEFnRtve7GkZZL+JumqiJiSpv9BsH1ll3XGJI1V7BNARbMOu+1PStoiaV1E/Nvu+B3AeSJiXNJ48Rp8QQe0ZFZDb7Y/oemgb46I3xWLj9keKeojko430yKAOvTcs3t6F/6UpD0R8dMZpa2S1kh6rLh9vpEOoQULFpTWly5dOqBOMJfN5jD+i5K+K2nS9o5i2XpNh/y3tu+TdFDStxvpEEAteoY9Iv4qqdsH9K/V2w6ApnC6LJAEYQeSIOxAEoQdSIKwA0nwU9IXgbKzGWd7piMufuzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtnngLvuuqu0XuXnwHtNybx79+6+XxvDhT07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPscMDk5WVp/6623utYWL15cuu7o6Ghp/fTp06V1zB3s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCfe6Ftr2qKRfSrpa0hlJ4xHxpO1HJH1P0rvFU9dHxO97vFb/F16jq5GRka61tWvXlq67d+/e0vrGjRv76gntiYiOkwXM5qSa05IejIg3bC+Q9LrtbUVtQ0T8pK4mATRnNvOzT0maKu6/b3uPpGubbgxAvS7oM7vtxZKWSfpbsegB2zttP217YZd1xmxP2J6o1iqAKmYddtuflLRF0rqI+Lekn0n6rKSbNb3nf6LTehExHhHLI2J59XYB9GtWYbf9CU0HfXNE/E6SIuJYRHwYEWck/VzSiubaBFBVz7B7ehrQpyTtiYifzlg+8yvgb0naVX97AOoym6G3L0n6i6RJTQ+9SdJ6Sas1fQgfkg5I+n7xZV7ZazH0BjSs29Bbz7DXibADzesWds6gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDHoKZv/JemfMx4vKpYNo2HtbVj7kuitX3X29pluhYFez37exu2JYf1tumHtbVj7kuitX4PqjcN4IAnCDiTRdtjHW95+mWHtbVj7kuitXwPprdXP7AAGp+09O4ABIexAEq2E3fZttvfafsf2Q2300I3tA7Ynbe9oe366Yg6947Z3zVh2he1ttt8ubjvOsddSb4/YPlK8dzts395Sb6O2/2x7j+03ba8tlrf63pX0NZD3beCf2W1fImmfpK9LOizpNUmrI2L3QBvpwvYBScsjovUTMGx/WdJ/JP0yIj5XLHtc0omIeKz4h3JhRPxwSHp7RNJ/2p7Gu5itaGTmNOOS7pB0r1p870r6+o4G8L61sWdfIemdiNgfEack/UbSqhb6GHoR8ZKkE+csXiVpU3F/k6b/Zxm4Lr0NhYiYiog3ivvvSzo7zXir711JXwPRRtivlXRoxuPDGq753kPSn2y/bnus7WY6uOrsNFvF7ZUt93OuntN4D9I504wPzXvXz/TnVbUR9k5T0wzT+N8XI+IWSd+UdH9xuIrZmdU03oPSYZrxodDv9OdVtRH2w5JGZzz+tKSjLfTRUUQcLW6PS3pOwzcV9bGzM+gWt8db7uf/hmka707TjGsI3rs2pz9vI+yvSbre9hLb8yTdLWlrC32cx/b84osT2Z4v6Rsavqmot0paU9xfI+n5Fnv5iGGZxrvbNONq+b1rffrziBj4n6TbNf2N/D8k/aiNHrr0dZ2kvxd/b7bdm6RnNH1Y919NHxHdJ+lTkrZLeru4vWKIevuVpqf23qnpYI201NuXNP3RcKekHcXf7W2/dyV9DeR943RZIAnOoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJP4HBr37rxL+/W0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(alpha_test_dataset[30][0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "3uAGwh1-3EKf"
   },
   "outputs": [],
   "source": [
    "if_score_list = []\n",
    "for i in range(training_size):\n",
    "    if_score = calculate_if(i, 30, inv_hessian)\n",
    "    if_score_list.append(if_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "zQP_kelD9l7P"
   },
   "outputs": [],
   "source": [
    "if_score_list_no_hessian = []\n",
    "for i in range(training_size):\n",
    "    if_score = calculate_if_no_hessian(i, 30)\n",
    "    if_score_list_no_hessian.append(if_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vthJINo05KaV",
    "outputId": "5cba7b21-623b-4510-8e9d-360de2ebe80b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4528     436.691276\n",
       "9822     429.115419\n",
       "11368    392.325760\n",
       "893      344.551329\n",
       "11781    342.638730\n",
       "            ...    \n",
       "5773    -330.725750\n",
       "5756    -338.761383\n",
       "8364    -430.982855\n",
       "9459    -525.030371\n",
       "994     -569.462098\n",
       "Length: 13007, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_score_series = pd.Series(if_score_list)\n",
    "if_score_series_sorted = if_score_series.sort_values(ascending = False)\n",
    "if_score_series_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "_uyHuoWU5O3o",
    "outputId": "b4bb932e-4ddf-4aa7-aac9-7351089acc4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0d4859ef70>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "axs[0][0].imshow(alpha_train_dataset[if_score_series_sorted.index[-1]][0], cmap = \"gray\")\n",
    "axs[0][1].imshow(alpha_train_dataset[if_score_series_sorted.index[-2]][0], cmap = \"gray\")\n",
    "axs[0][2].imshow(alpha_train_dataset[if_score_series_sorted.index[-3]][0], cmap = \"gray\")\n",
    "axs[1][0].imshow(alpha_train_dataset[if_score_series_sorted.index[0]][0], cmap = \"gray\")\n",
    "axs[1][1].imshow(alpha_train_dataset[if_score_series_sorted.index[1]][0], cmap = \"gray\")\n",
    "axs[1][2].imshow(alpha_train_dataset[if_score_series_sorted.index[2]][0], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jcNG5DZ5cNt",
    "outputId": "ecbbbb2e-7be0-45f2-87e8-f65dc6b02cba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_train_dataset[if_score_series_sorted.index[2]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ACud9V3O85_Y"
   },
   "outputs": [],
   "source": [
    "if_score_list_with_hessian = if_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13007"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(if_score_list_with_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "V83kpuB19Nmp",
    "outputId": "66ba6eed-1636-4202-e267-2a55e8122f14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0d4855f880>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(if_score_list_no_hessian,if_score_list_with_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "KRJxeVQv94XL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.18409358],\n",
       "       [0.18409358, 1.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(if_score_list_with_hessian, if_score_list_no_hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.341809720828467,\n",
       " 2.7888966489256526,\n",
       " 3.408776615789886,\n",
       " 2.3194309975471574,\n",
       " -0.15556116165863768,\n",
       " 8.048136152869139,\n",
       " 51.769925044693096,\n",
       " -46.380889875606954,\n",
       " -1.0732722151287057,\n",
       " 2.3659970569163917,\n",
       " -11.74838698596934,\n",
       " -0.014489078841847289,\n",
       " 2.049011964363215,\n",
       " 2.984415460817873,\n",
       " 5.648026885421373,\n",
       " -4.578495874600488,\n",
       " 2.030716970362593,\n",
       " 2.4150505874423387,\n",
       " 26.0274900369496,\n",
       " -8.256682127350352,\n",
       " -0.19269204602080547,\n",
       " -0.589129658860611,\n",
       " -1.4979734204683868,\n",
       " 20.694213138610742,\n",
       " -0.7968023543726596,\n",
       " 1.223465396503932,\n",
       " -0.1758644213788202,\n",
       " 5.497746341178858,\n",
       " 0.8465431970328441,\n",
       " 2.3245460536626097,\n",
       " 0.9565772871992413,\n",
       " -0.2661950278466634,\n",
       " 3.6981691186165166,\n",
       " 1.5908969383298337,\n",
       " 55.808397009237034,\n",
       " -15.489264772416728,\n",
       " -28.34830489777466,\n",
       " -8.780308615976939,\n",
       " 1.62480514911464,\n",
       " -0.25719122865168176,\n",
       " -24.044026838058876,\n",
       " 4.465487951232126,\n",
       " 17.266833844895473,\n",
       " 2.04168239785143,\n",
       " -0.10672687717821934,\n",
       " -0.3198305720285989,\n",
       " -0.013014796141129584,\n",
       " 3.6909998797414083,\n",
       " 14.975499587118843,\n",
       " 0.9336064073134531,\n",
       " 5.709265390247532,\n",
       " 2.1361712955562497,\n",
       " -58.05179081981224,\n",
       " -0.01681070962278195,\n",
       " -0.09188673571289828,\n",
       " 135.33516750240403,\n",
       " -0.628850172591571,\n",
       " 0.9560470931677814,\n",
       " -0.026193488741803092,\n",
       " 3.157243775396342,\n",
       " 6.9394271821819915,\n",
       " -2.1737955473557147,\n",
       " -0.019799342325295628,\n",
       " 1.1966309560145707,\n",
       " 2.220829662815907,\n",
       " 3.796029555642458,\n",
       " -0.13814799717395027,\n",
       " 1.7657644194161293,\n",
       " -0.08897395324756818,\n",
       " -0.36185090064822056,\n",
       " -0.30817731932122505,\n",
       " 1.6462592446245803,\n",
       " 2.1933100855364343,\n",
       " 4.581044770593412,\n",
       " -0.2286619497102204,\n",
       " -0.042091934853717365,\n",
       " -2.1727186024196636,\n",
       " 7.778451593471177,\n",
       " -0.04011149048865605,\n",
       " 9.071903485662649,\n",
       " -0.20849686834739833,\n",
       " 3.1888592126547213,\n",
       " 11.13701091018952,\n",
       " 4.287345469850198,\n",
       " 2.507872387658301,\n",
       " -170.1700488226623,\n",
       " -0.04236924779433989,\n",
       " -0.03113494238058758,\n",
       " 2.241845463632038,\n",
       " -3.96620621380605,\n",
       " -0.0907726078305364,\n",
       " 2.3580394517397796,\n",
       " 2.2999855771001503,\n",
       " 1.4203784381132138,\n",
       " 1.9379408674238312,\n",
       " 1.9626374925232501,\n",
       " -0.6099582691686491,\n",
       " 17.645896919982878,\n",
       " -6.647009193179959,\n",
       " -0.0790932139584262,\n",
       " -2.4114979565099275,\n",
       " 4.914687524552388,\n",
       " -0.05931203707648872,\n",
       " 2.0920100246808957,\n",
       " 1.2049272052228548,\n",
       " 2.522909941332094,\n",
       " 7.128986685702706,\n",
       " 6.326880066565902,\n",
       " -0.1601807589223309,\n",
       " -0.6564510424683422,\n",
       " 8.742294027236195,\n",
       " 3.3368675033798407,\n",
       " -2.9216620460536404,\n",
       " -1.1937306902926619,\n",
       " 2.1249139658244607,\n",
       " 10.444290515274519,\n",
       " 7.61330348391961,\n",
       " -13.650955821941952,\n",
       " -0.09222858136319773,\n",
       " 6.529059033967836,\n",
       " 3.253883168453717,\n",
       " 1.9133144564697426,\n",
       " -25.214039088148446,\n",
       " -15.289736681330453,\n",
       " -0.2680489244198093,\n",
       " -0.012931656155075657,\n",
       " 10.113410617696264,\n",
       " 6.043541293572703,\n",
       " 1.9001832396361302,\n",
       " 4.073093680808059,\n",
       " 3.194940114919609,\n",
       " 3.9998859043142665,\n",
       " -38.920228579729226,\n",
       " -0.19299359362527851,\n",
       " -1.013984097444578,\n",
       " 1.75763163927731,\n",
       " 8.029060556053642,\n",
       " -9.578131780666201,\n",
       " 2.075616959300172,\n",
       " 3.064679888400911,\n",
       " -1.0612186963902084,\n",
       " 9.464998431422904,\n",
       " -0.033931912865423186,\n",
       " 4.81410326471415,\n",
       " -98.2505896717022,\n",
       " -0.5694068917376642,\n",
       " 2.771622737619774,\n",
       " -0.5218336839578014,\n",
       " -0.06806127279306817,\n",
       " -22.924054300228526,\n",
       " -2.034917583351748,\n",
       " 2.761021193135746,\n",
       " 1.8628002556589247,\n",
       " -0.08443795386065266,\n",
       " -156.88766748141154,\n",
       " 5.291623259853776,\n",
       " -0.48306409562249175,\n",
       " -0.30077753362940196,\n",
       " 7.136018726000708,\n",
       " 1.8831492904525478,\n",
       " 2.969704683856774,\n",
       " -0.039732405118146664,\n",
       " -0.6626582205193219,\n",
       " 11.327286283333912,\n",
       " 0.8596867233925427,\n",
       " -0.04854123367210276,\n",
       " 0.8952394189531326,\n",
       " 1.500474445053603,\n",
       " -0.10708087987816448,\n",
       " -0.00923239736184995,\n",
       " -12.968500010307924,\n",
       " -0.27730245163995654,\n",
       " 4.5420112511389945,\n",
       " 2.9233327540040346,\n",
       " -0.5253599372026679,\n",
       " -0.46986555995277934,\n",
       " 0.49380795191800453,\n",
       " -0.09653712164838057,\n",
       " 0.7053893019941244,\n",
       " 2.055060656836542,\n",
       " 0.9684325627349184,\n",
       " -1.533895020734024,\n",
       " -1.8220874235008895,\n",
       " -0.13098241878104905,\n",
       " -0.5921347972155531,\n",
       " 0.8159026088856457,\n",
       " -0.039583103812079544,\n",
       " -0.05797606443180418,\n",
       " 2.9142993590994815,\n",
       " -6.52052764654898,\n",
       " 0.6016844504903631,\n",
       " 0.5405145302019989,\n",
       " 6.318372565790499,\n",
       " -0.33678583026963826,\n",
       " -0.1814295141941482,\n",
       " -0.9631906950962069,\n",
       " 18.910200466851347,\n",
       " 1.4752294162233168,\n",
       " -0.14572737640613975,\n",
       " -0.016696230812267746,\n",
       " -175.01773847974886,\n",
       " -0.7897270956564271,\n",
       " 1.932432173296153,\n",
       " -0.4976425909910141,\n",
       " -0.024172781995301512,\n",
       " 6.041009931664159,\n",
       " -0.26198284333663713,\n",
       " -0.336206808167272,\n",
       " -22.109136024181193,\n",
       " 0.7686012647996716,\n",
       " 1.6705067551332589,\n",
       " -0.15065050551753195,\n",
       " -9.883736045113027,\n",
       " -0.08471073540134211,\n",
       " -36.6225053451232,\n",
       " 1.6984244229937429,\n",
       " -0.11885890833523013,\n",
       " -23.462222237148914,\n",
       " -0.5312961131195342,\n",
       " 1.2457991624781866,\n",
       " -0.1855821477927921,\n",
       " 2.5070408304510057,\n",
       " 0.7310059068981228,\n",
       " -0.2368575747082594,\n",
       " -9.538162330061823,\n",
       " -0.04468351003188449,\n",
       " -9.931119770008753,\n",
       " 6.543611900857899,\n",
       " -0.03326728194836974,\n",
       " 4.697470478601396,\n",
       " 1.448339916506233,\n",
       " -0.02150870916152962,\n",
       " -1.592607468592707,\n",
       " -0.37452374276918876,\n",
       " 2.380082381358349,\n",
       " 1.4238301248000924,\n",
       " 2.5759822684466656,\n",
       " -0.10426281845706085,\n",
       " 2.854705523969428,\n",
       " -1.877367886644052,\n",
       " -3.4998965112799447,\n",
       " -34.80106627119687,\n",
       " 23.804906516902857,\n",
       " -4.260299165177802,\n",
       " -0.4650015894128222,\n",
       " 15.054190883741976,\n",
       " 4.576475376266346,\n",
       " 0.9699672137114173,\n",
       " -0.17245736332253675,\n",
       " -15.760532863235488,\n",
       " 3.3840156242578767,\n",
       " 2.7560257314609813,\n",
       " 3.205975899851481,\n",
       " -0.030671477392754297,\n",
       " -26.99768139172661,\n",
       " 20.389613386201475,\n",
       " 21.33488034969642,\n",
       " -1.4952298981606214,\n",
       " 0.8309436175940683,\n",
       " 3.298935276978474,\n",
       " -62.70114915452687,\n",
       " 14.015628733876087,\n",
       " -59.30765091236806,\n",
       " -0.15737606944341404,\n",
       " 1.8854538635153135,\n",
       " 2.1422444448081635,\n",
       " 2.619453222817524,\n",
       " -4.758140423790151,\n",
       " -5.051641934022462,\n",
       " -33.28641312294565,\n",
       " 3.696450249657402,\n",
       " 1.1122791337480553,\n",
       " 15.629504024591835,\n",
       " -15.990261822594505,\n",
       " -0.33576862857058365,\n",
       " 3.548570015104789,\n",
       " -0.29217548669967236,\n",
       " -7.514936896311225,\n",
       " -28.56743001487444,\n",
       " 3.7802497405979847,\n",
       " 1.3156263589571306,\n",
       " -0.24978726491345327,\n",
       " -0.06675847442480451,\n",
       " 3.911620040975282,\n",
       " 1.8117429408125671,\n",
       " 5.182129239786379,\n",
       " -0.3929511256510098,\n",
       " -0.007391173078188411,\n",
       " 3.980450674170963,\n",
       " -0.04235456381737113,\n",
       " -0.13998537796030533,\n",
       " -0.013285908527548863,\n",
       " -0.7109988155361544,\n",
       " 2.6887178276251724,\n",
       " -0.05485310891702466,\n",
       " 2.0627173352399533,\n",
       " 5.227062516888539,\n",
       " 25.31280637252769,\n",
       " -0.29871135530658477,\n",
       " 1.8749465975065445,\n",
       " 17.44381904613362,\n",
       " 6.752485613607864,\n",
       " -0.4777051679031652,\n",
       " 22.984856332882572,\n",
       " 6.269350219510972,\n",
       " -0.24933292572201043,\n",
       " -5.238402229786258,\n",
       " -0.036312009240392074,\n",
       " -0.018321450307138356,\n",
       " 2.658947018899453,\n",
       " -0.05376938204373434,\n",
       " -2.646687465071456,\n",
       " 2.4024234588128017,\n",
       " -0.10058884267406965,\n",
       " -0.354135731858966,\n",
       " -1.2145458764227264,\n",
       " -41.3801346357881,\n",
       " -0.054476758863545804,\n",
       " -0.5665873663534692,\n",
       " -0.05688309689697832,\n",
       " 1.88031351072543,\n",
       " 19.616788891415844,\n",
       " 2.2274062147016798,\n",
       " 131.35561717512405,\n",
       " -1.1598035283336945,\n",
       " -0.0974552418478165,\n",
       " -0.05422217411814054,\n",
       " 2.2263351667887323,\n",
       " -1.7685392265091906,\n",
       " 8.650154819734006,\n",
       " -0.49413471267342757,\n",
       " -0.4743512552770184,\n",
       " -0.04659372731428097,\n",
       " -0.24943792302829676,\n",
       " 3.9023657616149636,\n",
       " -0.0966381343459351,\n",
       " 4.5736370731359415,\n",
       " 1.2912642588731638,\n",
       " -0.36168499465704085,\n",
       " 3.4596125732523983,\n",
       " 4.399764815359281,\n",
       " 10.084722931449477,\n",
       " 3.9503164201702434,\n",
       " -0.06416070467966173,\n",
       " 3.4907567167262767,\n",
       " -15.1496130397075,\n",
       " 3.1080979160447466,\n",
       " 5.879262408180394,\n",
       " -0.999726779220214,\n",
       " -0.27815966355290106,\n",
       " 8.010000991061647,\n",
       " -0.9101702063429473,\n",
       " -0.9946357357213458,\n",
       " 2.939230418002034,\n",
       " 4.224253648149169,\n",
       " 3.736362181473101,\n",
       " 2.9596891866294412,\n",
       " -12.632170204241248,\n",
       " 2.311639758362076,\n",
       " -0.7569658684303016,\n",
       " -0.8215357337783094,\n",
       " 5.332136753877021,\n",
       " -3.436822429413007,\n",
       " -0.4507756730198579,\n",
       " 20.96653273983762,\n",
       " 3.904687098645661,\n",
       " 15.999353068315937,\n",
       " -0.4076583209638328,\n",
       " -0.6550298090938247,\n",
       " -0.15182042053233202,\n",
       " 21.95457987054847,\n",
       " -0.05123635682950643,\n",
       " -0.28382829193524833,\n",
       " 0.9207999598513477,\n",
       " 3.818773306824799,\n",
       " -1.4973204704227856,\n",
       " 1.7202381495868169,\n",
       " -0.09236038176950281,\n",
       " -129.13632342042834,\n",
       " 2.2632828548095807,\n",
       " 2.4630140849631936,\n",
       " -0.1093312657608276,\n",
       " 23.07869352218968,\n",
       " 19.89807519237192,\n",
       " 22.242719860622117,\n",
       " -0.23094760359752795,\n",
       " 3.3351550169506923,\n",
       " 3.900761802713161,\n",
       " 4.045267921777622,\n",
       " 2.490268790076332,\n",
       " 8.75062492449289,\n",
       " 2.6150678814409054,\n",
       " 3.681056586906603,\n",
       " 3.549631229624045,\n",
       " -0.10052464468918235,\n",
       " -0.8810824539632489,\n",
       " 1.8415305708610934,\n",
       " -0.20233932314255593,\n",
       " -0.32028810442764266,\n",
       " -0.16478443331193876,\n",
       " -0.8800014169756657,\n",
       " -16.574328226908044,\n",
       " 6.335251052478705,\n",
       " 2.5086183337464174,\n",
       " -0.24288941368444517,\n",
       " -0.22411388187034786,\n",
       " 1.9767979267260054,\n",
       " 1.5661077125427667,\n",
       " 6.244039885701106,\n",
       " -6.397386626569242,\n",
       " 1.1259486755915389,\n",
       " -0.1594754862788911,\n",
       " 3.1191671790519555,\n",
       " -46.77221659173986,\n",
       " -0.06191628851449575,\n",
       " 2.364667501728674,\n",
       " 7.689968516210127,\n",
       " -174.88113879556232,\n",
       " -0.09868105838723908,\n",
       " -0.00603531349730633,\n",
       " -0.32161676610616485,\n",
       " 1.3365768644487797,\n",
       " 0.8769505516447017,\n",
       " -0.040644749914353635,\n",
       " 29.44990442053608,\n",
       " -0.06985407399961882,\n",
       " -2.745785391930248,\n",
       " 11.559158218493408,\n",
       " 1.9188404888618502,\n",
       " 1.164090698730808,\n",
       " -0.22634282979387327,\n",
       " -0.051753743877107544,\n",
       " 1.74784920784799,\n",
       " 3.420367420354123,\n",
       " -0.49198647524230193,\n",
       " 4.057162953604313,\n",
       " -0.9683650783537749,\n",
       " -0.025966003576959423,\n",
       " -2.455829556934322,\n",
       " -0.24779840857936028,\n",
       " 7.82754681116264,\n",
       " -0.9867037468314704,\n",
       " -0.002266597508422799,\n",
       " 4.890022992250806,\n",
       " -0.0020901479848272867,\n",
       " 3.866048932316711,\n",
       " 2.5765837607800672,\n",
       " -0.11251987324444243,\n",
       " 0.590901740205894,\n",
       " -57.4108428994979,\n",
       " -0.10647804255339301,\n",
       " -0.011681790098819712,\n",
       " 15.02192757804793,\n",
       " 21.858510138607876,\n",
       " 2.8350438747353675,\n",
       " 8.681052172984792,\n",
       " -1.8932473733149355,\n",
       " -0.8411451503155418,\n",
       " -0.15301975878400378,\n",
       " -12.361925627303535,\n",
       " 2.901377879044794,\n",
       " 3.4373770213956596,\n",
       " -0.011593327889508443,\n",
       " 4.735086490997432,\n",
       " -0.04663489121684376,\n",
       " -0.915915101374346,\n",
       " 1.6113844382659201,\n",
       " -102.79471806901972,\n",
       " 3.5329982476860966,\n",
       " -0.07210670645877269,\n",
       " -0.13597602039884665,\n",
       " 3.025758078355432,\n",
       " 1.388209148475643,\n",
       " -0.0034099073206425544,\n",
       " 16.188145997662765,\n",
       " 3.151217684352898,\n",
       " -0.8386418165754602,\n",
       " -0.023811766741316888,\n",
       " 2.0486729219827193,\n",
       " 1.5575463188662735,\n",
       " 0.8981732026038789,\n",
       " -0.03225547097358406,\n",
       " 3.3153845934176953,\n",
       " 16.48106385742926,\n",
       " -33.04192930804095,\n",
       " -0.018538005707267047,\n",
       " 7.246325633976831,\n",
       " -0.06302405488443802,\n",
       " 1.5281361499104587,\n",
       " 6.418851035359902,\n",
       " 7.604209720133671,\n",
       " 46.20848995060524,\n",
       " -0.8780477830525144,\n",
       " -0.16388276069287488,\n",
       " 0.8021648607877901,\n",
       " 3.776212772514774,\n",
       " -0.005559202191118818,\n",
       " -0.7591570785826856,\n",
       " -1.9423575645533515,\n",
       " -0.022153560758696907,\n",
       " 2.0687899842221515,\n",
       " 2.568142225296634,\n",
       " -0.030716933658719733,\n",
       " 0.007160422473796876,\n",
       " -0.126072330486312,\n",
       " 6.100023872633701,\n",
       " 10.024564555085528,\n",
       " 2.0660022817151775,\n",
       " 3.825072440812108,\n",
       " 1.3458485987846094,\n",
       " -0.02963631546264489,\n",
       " 3.3177462961857453,\n",
       " 1.590490238671304,\n",
       " 7.699705050688946,\n",
       " -0.03922474801694362,\n",
       " -0.6037290354202631,\n",
       " -1.62027266664097,\n",
       " 4.552758444576568,\n",
       " 2.142706557783186,\n",
       " 1.2477249568728648,\n",
       " 2.4533230808913786,\n",
       " -0.5677536268974183,\n",
       " 0.9845206024616391,\n",
       " 3.834313957255711,\n",
       " -16.53530120552052,\n",
       " -0.11015239765577764,\n",
       " -0.8878159749400745,\n",
       " -0.656372896818094,\n",
       " -0.277952108156019,\n",
       " 1.0775132322005434,\n",
       " 2.3786813965194673,\n",
       " 3.9316379874968126,\n",
       " -0.09505273571204026,\n",
       " 7.60071515869834,\n",
       " 61.402278460853495,\n",
       " -0.8546442410594808,\n",
       " 2.3204066535024905,\n",
       " -0.19435800391296812,\n",
       " 4.120847520710956,\n",
       " -0.5480660988141766,\n",
       " 0.5194588915853517,\n",
       " 3.6579574074745067,\n",
       " -1.219541576099707,\n",
       " 6.266877763377785,\n",
       " -0.49608275438231114,\n",
       " 1.2782772296666063,\n",
       " -0.5201818914563829,\n",
       " -1.4871475684687523,\n",
       " -1.7359617132879077,\n",
       " -7.587107620372332,\n",
       " 3.308416572902047,\n",
       " 0.5908196723339839,\n",
       " -9.862200623916062,\n",
       " 2.19602464381702,\n",
       " -4.843374948355572,\n",
       " -1.7781186039291703,\n",
       " 5.254889603899741,\n",
       " -0.0920497662495658,\n",
       " -0.7286604887341424,\n",
       " 4.281980634624237,\n",
       " 3.2174887743084337,\n",
       " -0.436832280914076,\n",
       " 9.355931892405696,\n",
       " 2.7179461807456864,\n",
       " -1.02791636747993,\n",
       " -0.636347715291397,\n",
       " -1.2839306939008033,\n",
       " 2.5700366268160995,\n",
       " -0.3189775796709327,\n",
       " 1.761984158545495,\n",
       " 1.0340666173004325,\n",
       " 6.247346565491461,\n",
       " -33.39666736606192,\n",
       " -0.19196478050589222,\n",
       " 3.042494536567048,\n",
       " -11.089076809630178,\n",
       " 0.6527930650883502,\n",
       " 8.96629118267438,\n",
       " 3.152233815369674,\n",
       " -11.30785651606977,\n",
       " 3.493991120278884,\n",
       " -0.0032905804703598288,\n",
       " -0.08412607835112319,\n",
       " 8.708503544382662,\n",
       " -0.10132371387062142,\n",
       " -0.18477447963207738,\n",
       " 7.280940554383248,\n",
       " -1.7556401386151501,\n",
       " 2.1110075964851123,\n",
       " -0.543481510523069,\n",
       " -57.99371864169014,\n",
       " 2.469862694543755,\n",
       " -0.3222626828072528,\n",
       " 2.103915111659278,\n",
       " 5.299319885033277,\n",
       " -0.171305195142627,\n",
       " -0.0871556013887144,\n",
       " -2.1464426715302904,\n",
       " 2.2335219397238966,\n",
       " -0.5428196889443737,\n",
       " 1.2856227739955925,\n",
       " 6.659134260177158,\n",
       " 5.6728476883971535,\n",
       " 3.575155939189742,\n",
       " 5.810617373056087,\n",
       " 3.0721178480605102,\n",
       " -0.07503073496154483,\n",
       " 1.9595319702810103,\n",
       " -0.06368278965266895,\n",
       " -0.34972913169302133,\n",
       " -1.3400345409056134,\n",
       " -0.1127426276174335,\n",
       " 2.4311229311591185,\n",
       " -6.223351928494488,\n",
       " 5.352788929005492,\n",
       " 2.8723683860529166,\n",
       " -0.3525209666773348,\n",
       " 0.6654689560736566,\n",
       " 8.830137042995108,\n",
       " 2.519496035624968,\n",
       " 3.0674524311562528,\n",
       " 2.176371936759121,\n",
       " -0.3815373549967103,\n",
       " 24.226517079891636,\n",
       " -0.12059958184962787,\n",
       " 2.278951034394459,\n",
       " 15.279519889939774,\n",
       " -0.006365163991461304,\n",
       " 24.33090010332929,\n",
       " -57.25855924952356,\n",
       " -0.03746834935319817,\n",
       " -11.594769392928821,\n",
       " 2.560869733885883,\n",
       " 22.874231275348073,\n",
       " -0.011357032894022234,\n",
       " -0.07582901499632463,\n",
       " 4.297255006704669,\n",
       " 1.5179922356588171,\n",
       " 2.0292262588162897,\n",
       " 1.9599558179542478,\n",
       " -0.037927238488154574,\n",
       " 7.272002735785021,\n",
       " 1.093348306075368,\n",
       " -0.34175181671888505,\n",
       " 3.6994268336213127,\n",
       " 32.66847106446643,\n",
       " -0.04329210251546675,\n",
       " 10.867342274109156,\n",
       " 1.1112260210220803,\n",
       " -0.5302499830673195,\n",
       " 5.690245460264679,\n",
       " 6.722909364848504,\n",
       " 2.530606185417044,\n",
       " -0.6205151203548201,\n",
       " -3.0190903980484,\n",
       " 2.3622780387682702,\n",
       " -0.28841274841136955,\n",
       " 1.3832261741833272,\n",
       " 0.935559121392563,\n",
       " -182.97427011185678,\n",
       " -0.391637412841373,\n",
       " -0.2329767934487883,\n",
       " -0.4565639206471084,\n",
       " -0.2626079467844985,\n",
       " 1.4980894754631668,\n",
       " 9.691581703059086,\n",
       " -0.2432544210252648,\n",
       " 3.380945601464603,\n",
       " 2.557557203063748,\n",
       " -0.43470266200444696,\n",
       " -112.41487385551571,\n",
       " 7.201706590074356,\n",
       " 7.0714997859404995,\n",
       " 9.024045330642464,\n",
       " -0.26537713081717357,\n",
       " -106.08517094159501,\n",
       " -54.74974143092325,\n",
       " 2.0215918091026657,\n",
       " 22.734024869935304,\n",
       " -4.705043112729685,\n",
       " 10.214030351764604,\n",
       " -0.3544745218170327,\n",
       " -1.572590684860811,\n",
       " 2.4016535293296397,\n",
       " 3.228152074839277,\n",
       " 1.093275858300602,\n",
       " -0.15092064696634708,\n",
       " 4.060910280952164,\n",
       " 1.0242173995762474,\n",
       " 3.6401394129416156,\n",
       " 2.79482862859437,\n",
       " -44.39750845930588,\n",
       " 8.78114094175957,\n",
       " 1.1465722662872877,\n",
       " -0.12302322040909604,\n",
       " 1.7479059956527638,\n",
       " -0.25022131820541027,\n",
       " -1.0949241525886009,\n",
       " 1.0743990938871015,\n",
       " -1.62340440246119,\n",
       " 2.6273089414199156,\n",
       " -4.2637090808285425,\n",
       " -0.8621577643929551,\n",
       " -9.927289964345466,\n",
       " 2.360737048021652,\n",
       " -0.44821913484229514,\n",
       " -0.467381344497417,\n",
       " 1.3360041710718051,\n",
       " -0.11121894993828406,\n",
       " 1.5979678474359136,\n",
       " 1.7124403360162364,\n",
       " -0.4190639334344904,\n",
       " 3.2620338769126853,\n",
       " -0.3745524008884241,\n",
       " -0.3061966102032996,\n",
       " -0.014533416065924159,\n",
       " -52.81635017344815,\n",
       " -0.0452814652645216,\n",
       " -3.284955174059996,\n",
       " -6.379012429167506,\n",
       " -0.7073047528824483,\n",
       " 3.7155050206735596,\n",
       " -6.288382890755648,\n",
       " -0.3240270487450859,\n",
       " -0.02767342632752244,\n",
       " 2.1219299986512663,\n",
       " -0.16994062458618725,\n",
       " 4.414789823387314,\n",
       " -0.2961970773283524,\n",
       " 7.867630450936996,\n",
       " -0.027658915364433136,\n",
       " 18.066308680183205,\n",
       " -0.06251612415784599,\n",
       " 4.037825520197799,\n",
       " 2.3066345010280003,\n",
       " -0.7000478718328502,\n",
       " -0.3503511185014765,\n",
       " -7.486910108684291,\n",
       " 3.8763783470043154,\n",
       " 1.2051102652134782,\n",
       " 2.807099605896786,\n",
       " 2.214089264348586,\n",
       " 3.2409756227193123,\n",
       " 2.2368374019932515,\n",
       " -15.501193255642466,\n",
       " 2.0067774873386366,\n",
       " -81.65272277825476,\n",
       " 3.9489578463425112,\n",
       " 11.88574860907231,\n",
       " 3.552659434000168,\n",
       " -0.3179078936862444,\n",
       " -0.010669126358600668,\n",
       " 4.171097174041805,\n",
       " -3.054624634454914,\n",
       " 1.8863251795482083,\n",
       " 4.054621223891125,\n",
       " 1.6896751089202378,\n",
       " -0.5724993981712181,\n",
       " -1.3986189500945385,\n",
       " 37.7003610623448,\n",
       " -0.8076415175837992,\n",
       " 1.8154958070182021,\n",
       " 4.64976415967954,\n",
       " -1.4980205883322575,\n",
       " 2.476440314123578,\n",
       " 2.229909188477629,\n",
       " 15.176831836346516,\n",
       " 3.1477884680072528,\n",
       " -103.02423726055655,\n",
       " -0.5935348574198474,\n",
       " -0.2332358893211814,\n",
       " -1.9672887034695448,\n",
       " 4.390415217892263,\n",
       " -0.2878118889582377,\n",
       " -1.5484940244484693,\n",
       " -11.897689205696832,\n",
       " -0.18932125130741456,\n",
       " 24.601228877878956,\n",
       " -1.1898623987018984,\n",
       " 2.7573093314625665,\n",
       " 8.81638834625354,\n",
       " 2.839377411484181,\n",
       " 4.0780816476514765,\n",
       " 23.167166145649798,\n",
       " -1.2172750596834438,\n",
       " 0.9607847060925994,\n",
       " 1.8753439810156285,\n",
       " 0.7750538270784991,\n",
       " -0.3427118667032053,\n",
       " 2.0250136775045675,\n",
       " 2.1887564514689437,\n",
       " 2.454970645366615,\n",
       " -0.22006353825776542,\n",
       " 3.0059271178209857,\n",
       " 3.0299095742199134,\n",
       " 3.157194973327492,\n",
       " -0.33662565906928466,\n",
       " -0.1481705320086564,\n",
       " -0.13938165968125912,\n",
       " 0.6588318821431279,\n",
       " -2.7242686683690565,\n",
       " -6.50882726823901,\n",
       " -0.041321204947494417,\n",
       " 11.146425806776978,\n",
       " 1.0696758784847704,\n",
       " -222.63832947009837,\n",
       " 39.67718813550428,\n",
       " 2.1856696171850114,\n",
       " -1.150082877427736,\n",
       " -0.798898109857421,\n",
       " 1.1509836891403298,\n",
       " 1.443788027956459,\n",
       " -18.73097383618324,\n",
       " 1.4168537315479572,\n",
       " -0.08831681522747115,\n",
       " 4.128939317982402,\n",
       " -0.046715043259673725,\n",
       " -2.0646926064151483,\n",
       " -0.6179976646820144,\n",
       " 3.7124600660366776,\n",
       " 1.4825426814543368,\n",
       " 2.8317253939823233,\n",
       " -0.3124346380525267,\n",
       " 5.114534795049524,\n",
       " -0.5573413393401286,\n",
       " -0.3661963789868734,\n",
       " -0.40566844269480473,\n",
       " -0.4944654290199447,\n",
       " -2.4980766245495545,\n",
       " 15.599863581283046,\n",
       " -77.19287947541892,\n",
       " 5.529222080012121,\n",
       " 2.511503974778091,\n",
       " -1.8644799055417087,\n",
       " -0.27549687260543,\n",
       " 14.684618857569308,\n",
       " 1.5433619564193675,\n",
       " -0.06054610366469474,\n",
       " 3.261310484401297,\n",
       " -49.285440757396216,\n",
       " -0.1744760471650335,\n",
       " -1.3136219053842675,\n",
       " 1.4050067059450173,\n",
       " 2.0750813849624663,\n",
       " -0.18279851183738652,\n",
       " -34.81244962154557,\n",
       " -1.5562108067507783,\n",
       " 6.218019391654989,\n",
       " 6.254788491321582,\n",
       " -0.319369928854581,\n",
       " 12.16743559489936,\n",
       " -0.007410667576768383,\n",
       " -15.922866938025411,\n",
       " 2.3244466232515935,\n",
       " 6.76499453625236,\n",
       " -0.2781812025867016,\n",
       " 3.3791123903663984,\n",
       " 1.1292294253514776,\n",
       " -0.8986812677454012,\n",
       " -6.820035080059813,\n",
       " -0.9556229964786785,\n",
       " -4.199304080195251,\n",
       " 2.385721923773159,\n",
       " -39.015234040038045,\n",
       " -4.349331806087737,\n",
       " -1.968370450909921,\n",
       " -9.744291938205329,\n",
       " -0.37235904623556904,\n",
       " 1.5199902356021904,\n",
       " 8.597551531494435,\n",
       " 1.696171385455353,\n",
       " 4.671800902622348,\n",
       " 5.54485465743471,\n",
       " 5.045740341531119,\n",
       " 1.941398460577541,\n",
       " -0.2498182856190807,\n",
       " 4.1392373967460685,\n",
       " -1.3736466819900905,\n",
       " 0.875957186474347,\n",
       " 2.162925378623602,\n",
       " 1.630875208642145,\n",
       " 1.907546191213742,\n",
       " 60.68679068523039,\n",
       " -0.2289701517390374,\n",
       " -2.638296829038973,\n",
       " 13.1874730126276,\n",
       " -1.098170880211812,\n",
       " -0.01795393338357957,\n",
       " -1.4516485021840935,\n",
       " -0.07876030595437171,\n",
       " 1.2776467809834116,\n",
       " -0.538280133181696,\n",
       " 9.461463496088388,\n",
       " 144.375371593256,\n",
       " 2.9012022961768293,\n",
       " 2.9561275258856186,\n",
       " -1.122478774135821,\n",
       " -0.07396045780770376,\n",
       " 2.541919242674164,\n",
       " 4.800743614357495,\n",
       " 9.031860345212184,\n",
       " -3.691204863656238,\n",
       " 2.2245767167761645,\n",
       " 9.298044324514125,\n",
       " 5.846538317017357,\n",
       " -0.27507061833122726,\n",
       " -0.3408331186044856,\n",
       " 44.1108388998431,\n",
       " 6.806879848039101,\n",
       " -0.3080303467799128,\n",
       " 13.571971954928348,\n",
       " 3.3537240155385173,\n",
       " 21.150084818548493,\n",
       " 1.147162919408072,\n",
       " 4.723678334952141,\n",
       " -0.050419852711933624,\n",
       " 4.756374947708614,\n",
       " -0.0745421256152748,\n",
       " -0.03195876424877957,\n",
       " 2.2149466842915078,\n",
       " -0.16339694123542944,\n",
       " 3.38396810363177,\n",
       " 43.249226952328215,\n",
       " -7.525660157503555,\n",
       " 3.0117617000160326,\n",
       " -0.3887297053910471,\n",
       " -0.021496672117359665,\n",
       " -0.09760179437413846,\n",
       " 9.652026260689354,\n",
       " -0.20375439092408537,\n",
       " -0.03310353392764671,\n",
       " 10.38909139640518,\n",
       " -0.17398437013196305,\n",
       " 14.62244350298777,\n",
       " -0.04729927863345039,\n",
       " -0.03595972760268596,\n",
       " -4.963204505641399,\n",
       " 1.8190300509764268,\n",
       " -0.8996807047692585,\n",
       " -9.79123733210154,\n",
       " -0.27478093929184544,\n",
       " 1.7666538877096292,\n",
       " 1.3683409176159507,\n",
       " 1.7224517226871503,\n",
       " -0.2158317020925233,\n",
       " -0.03937934535640486,\n",
       " 1.1643352283332056,\n",
       " -0.6345782841360209,\n",
       " 0.6266150702310065,\n",
       " -2.464821986485589,\n",
       " 1.4043015559396368,\n",
       " -0.38041338797949453,\n",
       " -0.21158008549384916,\n",
       " -1.6894001261741871,\n",
       " -7.897235107986373,\n",
       " 1.3012784120476555,\n",
       " -0.6251286601619745,\n",
       " -0.7944344133800165,\n",
       " 0.6815231724320819,\n",
       " -0.36297283818924453,\n",
       " -0.5455789413299843,\n",
       " -0.5928274712978752,\n",
       " -0.6316018886629339,\n",
       " -4.520094950623726,\n",
       " -0.4649628846479199,\n",
       " -0.217077241969412,\n",
       " 1.2308942577568431,\n",
       " 3.7657592533672073,\n",
       " -0.21394135104804124,\n",
       " -1.0136389808174533,\n",
       " -0.3654065250355668,\n",
       " -0.4693279615961001,\n",
       " 1.9915863808242367,\n",
       " 7.425027972401556,\n",
       " 2.5697772040869085,\n",
       " 1.6271729115568068,\n",
       " -1.0094278555815195,\n",
       " -0.8298191801368884,\n",
       " -0.8557471104766055,\n",
       " 7.83095423781539,\n",
       " 8.518711858652184,\n",
       " 12.425562374124608,\n",
       " -0.12381731650501997,\n",
       " -1.2126262658570617,\n",
       " 4.055561391528025,\n",
       " 6.363578308446293,\n",
       " -0.04162955958467687,\n",
       " -1.9670623235629503,\n",
       " -1.3427477732727788,\n",
       " 7.012753021345617,\n",
       " 6.015892176868263,\n",
       " 6.511295110744889,\n",
       " 6.152284104477297,\n",
       " -0.007923364909139245,\n",
       " 123.58070700612986,\n",
       " 1.4614204512676372,\n",
       " 1.35501467424834,\n",
       " -1.3087710153657535,\n",
       " -0.03714853332195326,\n",
       " 4.664209776753864,\n",
       " ...]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_score_list_no_hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "LMMPQJ0NLwkl",
    "4d6uUU5rMMQQ",
    "5CXudkreNaa_",
    "vIaZsTl3FKSm",
    "iUgBl19jcTQ4",
    "RovowtXlcYWQ",
    "JkZeYRSgmGdT",
    "E6nnnFs5CvmG",
    "ztRLeHRdKiq1",
    "SF9GWBxRIVvR",
    "bg-5feqZjxZI"
   ],
   "machine_shape": "hm",
   "name": "Influence_function.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
